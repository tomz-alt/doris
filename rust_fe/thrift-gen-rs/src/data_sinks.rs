// Autogenerated by Thrift Compiler (0.19.0)
// DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING

#![allow(dead_code)]
#![allow(unused_imports)]
#![allow(unused_extern_crates)]
#![allow(clippy::too_many_arguments, clippy::type_complexity, clippy::vec_box, clippy::wrong_self_convention)]
#![cfg_attr(rustfmt, rustfmt_skip)]

use std::cell::RefCell;
use std::collections::{BTreeMap, BTreeSet};
use std::convert::{From, TryFrom};
use std::default::Default;
use std::error::Error;
use std::fmt;
use std::fmt::{Display, Formatter};
use std::rc::Rc;

use thrift::OrderedFloat;
use thrift::{ApplicationError, ApplicationErrorKind, ProtocolError, ProtocolErrorKind, TThriftClient};
use thrift::protocol::{TFieldIdentifier, TListIdentifier, TMapIdentifier, TMessageIdentifier, TMessageType, TInputProtocol, TOutputProtocol, TSerializable, TSetIdentifier, TStructIdentifier, TType};
use thrift::protocol::field_id;
use thrift::protocol::verify_expected_message_type;
use thrift::protocol::verify_expected_sequence_number;
use thrift::protocol::verify_expected_service_call;
use thrift::protocol::verify_required_field_exists;
use thrift::server::TProcessor;

use crate::descriptors;
use crate::exprs;
use crate::partitions;
use crate::plan_nodes;
use crate::types;

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TDataSinkType(pub i32);

impl TDataSinkType {
  pub const DATA_STREAM_SINK: TDataSinkType = TDataSinkType(0);
  pub const RESULT_SINK: TDataSinkType = TDataSinkType(1);
  pub const DATA_SPLIT_SINK: TDataSinkType = TDataSinkType(2);
  pub const MYSQL_TABLE_SINK: TDataSinkType = TDataSinkType(3);
  pub const EXPORT_SINK: TDataSinkType = TDataSinkType(4);
  pub const OLAP_TABLE_SINK: TDataSinkType = TDataSinkType(5);
  pub const MEMORY_SCRATCH_SINK: TDataSinkType = TDataSinkType(6);
  pub const ODBC_TABLE_SINK: TDataSinkType = TDataSinkType(7);
  pub const RESULT_FILE_SINK: TDataSinkType = TDataSinkType(8);
  pub const JDBC_TABLE_SINK: TDataSinkType = TDataSinkType(9);
  pub const MULTI_CAST_DATA_STREAM_SINK: TDataSinkType = TDataSinkType(10);
  pub const GROUP_COMMIT_OLAP_TABLE_SINK: TDataSinkType = TDataSinkType(11);
  pub const GROUP_COMMIT_BLOCK_SINK: TDataSinkType = TDataSinkType(12);
  pub const HIVE_TABLE_SINK: TDataSinkType = TDataSinkType(13);
  pub const ICEBERG_TABLE_SINK: TDataSinkType = TDataSinkType(14);
  pub const DICTIONARY_SINK: TDataSinkType = TDataSinkType(15);
  pub const BLACKHOLE_SINK: TDataSinkType = TDataSinkType(16);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::DATA_STREAM_SINK,
    Self::RESULT_SINK,
    Self::DATA_SPLIT_SINK,
    Self::MYSQL_TABLE_SINK,
    Self::EXPORT_SINK,
    Self::OLAP_TABLE_SINK,
    Self::MEMORY_SCRATCH_SINK,
    Self::ODBC_TABLE_SINK,
    Self::RESULT_FILE_SINK,
    Self::JDBC_TABLE_SINK,
    Self::MULTI_CAST_DATA_STREAM_SINK,
    Self::GROUP_COMMIT_OLAP_TABLE_SINK,
    Self::GROUP_COMMIT_BLOCK_SINK,
    Self::HIVE_TABLE_SINK,
    Self::ICEBERG_TABLE_SINK,
    Self::DICTIONARY_SINK,
    Self::BLACKHOLE_SINK,
  ];
}

impl TSerializable for TDataSinkType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TDataSinkType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TDataSinkType::from(enum_value))
  }
}

impl From<i32> for TDataSinkType {
  fn from(i: i32) -> Self {
    match i {
      0 => TDataSinkType::DATA_STREAM_SINK,
      1 => TDataSinkType::RESULT_SINK,
      2 => TDataSinkType::DATA_SPLIT_SINK,
      3 => TDataSinkType::MYSQL_TABLE_SINK,
      4 => TDataSinkType::EXPORT_SINK,
      5 => TDataSinkType::OLAP_TABLE_SINK,
      6 => TDataSinkType::MEMORY_SCRATCH_SINK,
      7 => TDataSinkType::ODBC_TABLE_SINK,
      8 => TDataSinkType::RESULT_FILE_SINK,
      9 => TDataSinkType::JDBC_TABLE_SINK,
      10 => TDataSinkType::MULTI_CAST_DATA_STREAM_SINK,
      11 => TDataSinkType::GROUP_COMMIT_OLAP_TABLE_SINK,
      12 => TDataSinkType::GROUP_COMMIT_BLOCK_SINK,
      13 => TDataSinkType::HIVE_TABLE_SINK,
      14 => TDataSinkType::ICEBERG_TABLE_SINK,
      15 => TDataSinkType::DICTIONARY_SINK,
      16 => TDataSinkType::BLACKHOLE_SINK,
      _ => TDataSinkType(i)
    }
  }
}

impl From<&i32> for TDataSinkType {
  fn from(i: &i32) -> Self {
    TDataSinkType::from(*i)
  }
}

impl From<TDataSinkType> for i32 {
  fn from(e: TDataSinkType) -> i32 {
    e.0
  }
}

impl From<&TDataSinkType> for i32 {
  fn from(e: &TDataSinkType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TResultSinkType(pub i32);

impl TResultSinkType {
  pub const MYSQL_PROTOCOL: TResultSinkType = TResultSinkType(0);
  pub const ARROW_FLIGHT_PROTOCOL: TResultSinkType = TResultSinkType(1);
  pub const FILE: TResultSinkType = TResultSinkType(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::MYSQL_PROTOCOL,
    Self::ARROW_FLIGHT_PROTOCOL,
    Self::FILE,
  ];
}

impl TSerializable for TResultSinkType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TResultSinkType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TResultSinkType::from(enum_value))
  }
}

impl From<i32> for TResultSinkType {
  fn from(i: i32) -> Self {
    match i {
      0 => TResultSinkType::MYSQL_PROTOCOL,
      1 => TResultSinkType::ARROW_FLIGHT_PROTOCOL,
      2 => TResultSinkType::FILE,
      _ => TResultSinkType(i)
    }
  }
}

impl From<&i32> for TResultSinkType {
  fn from(i: &i32) -> Self {
    TResultSinkType::from(*i)
  }
}

impl From<TResultSinkType> for i32 {
  fn from(e: TResultSinkType) -> i32 {
    e.0
  }
}

impl From<&TResultSinkType> for i32 {
  fn from(e: &TResultSinkType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetCompressionType(pub i32);

impl TParquetCompressionType {
  pub const SNAPPY: TParquetCompressionType = TParquetCompressionType(0);
  pub const GZIP: TParquetCompressionType = TParquetCompressionType(1);
  pub const BROTLI: TParquetCompressionType = TParquetCompressionType(2);
  pub const ZSTD: TParquetCompressionType = TParquetCompressionType(3);
  pub const LZ4: TParquetCompressionType = TParquetCompressionType(4);
  pub const LZO: TParquetCompressionType = TParquetCompressionType(5);
  pub const BZ2: TParquetCompressionType = TParquetCompressionType(6);
  pub const UNCOMPRESSED: TParquetCompressionType = TParquetCompressionType(7);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::SNAPPY,
    Self::GZIP,
    Self::BROTLI,
    Self::ZSTD,
    Self::LZ4,
    Self::LZO,
    Self::BZ2,
    Self::UNCOMPRESSED,
  ];
}

impl TSerializable for TParquetCompressionType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetCompressionType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TParquetCompressionType::from(enum_value))
  }
}

impl From<i32> for TParquetCompressionType {
  fn from(i: i32) -> Self {
    match i {
      0 => TParquetCompressionType::SNAPPY,
      1 => TParquetCompressionType::GZIP,
      2 => TParquetCompressionType::BROTLI,
      3 => TParquetCompressionType::ZSTD,
      4 => TParquetCompressionType::LZ4,
      5 => TParquetCompressionType::LZO,
      6 => TParquetCompressionType::BZ2,
      7 => TParquetCompressionType::UNCOMPRESSED,
      _ => TParquetCompressionType(i)
    }
  }
}

impl From<&i32> for TParquetCompressionType {
  fn from(i: &i32) -> Self {
    TParquetCompressionType::from(*i)
  }
}

impl From<TParquetCompressionType> for i32 {
  fn from(e: TParquetCompressionType) -> i32 {
    e.0
  }
}

impl From<&TParquetCompressionType> for i32 {
  fn from(e: &TParquetCompressionType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetVersion(pub i32);

impl TParquetVersion {
  pub const PARQUET_1_0: TParquetVersion = TParquetVersion(0);
  pub const PARQUET_2_LATEST: TParquetVersion = TParquetVersion(1);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::PARQUET_1_0,
    Self::PARQUET_2_LATEST,
  ];
}

impl TSerializable for TParquetVersion {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetVersion> {
    let enum_value = i_prot.read_i32()?;
    Ok(TParquetVersion::from(enum_value))
  }
}

impl From<i32> for TParquetVersion {
  fn from(i: i32) -> Self {
    match i {
      0 => TParquetVersion::PARQUET_1_0,
      1 => TParquetVersion::PARQUET_2_LATEST,
      _ => TParquetVersion(i)
    }
  }
}

impl From<&i32> for TParquetVersion {
  fn from(i: &i32) -> Self {
    TParquetVersion::from(*i)
  }
}

impl From<TParquetVersion> for i32 {
  fn from(e: TParquetVersion) -> i32 {
    e.0
  }
}

impl From<&TParquetVersion> for i32 {
  fn from(e: &TParquetVersion) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetDataType(pub i32);

impl TParquetDataType {
  pub const BOOLEAN: TParquetDataType = TParquetDataType(0);
  pub const INT32: TParquetDataType = TParquetDataType(1);
  pub const INT64: TParquetDataType = TParquetDataType(2);
  pub const INT96: TParquetDataType = TParquetDataType(3);
  pub const BYTE_ARRAY: TParquetDataType = TParquetDataType(4);
  pub const FLOAT: TParquetDataType = TParquetDataType(5);
  pub const DOUBLE: TParquetDataType = TParquetDataType(6);
  pub const FIXED_LEN_BYTE_ARRAY: TParquetDataType = TParquetDataType(7);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::BOOLEAN,
    Self::INT32,
    Self::INT64,
    Self::INT96,
    Self::BYTE_ARRAY,
    Self::FLOAT,
    Self::DOUBLE,
    Self::FIXED_LEN_BYTE_ARRAY,
  ];
}

impl TSerializable for TParquetDataType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetDataType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TParquetDataType::from(enum_value))
  }
}

impl From<i32> for TParquetDataType {
  fn from(i: i32) -> Self {
    match i {
      0 => TParquetDataType::BOOLEAN,
      1 => TParquetDataType::INT32,
      2 => TParquetDataType::INT64,
      3 => TParquetDataType::INT96,
      4 => TParquetDataType::BYTE_ARRAY,
      5 => TParquetDataType::FLOAT,
      6 => TParquetDataType::DOUBLE,
      7 => TParquetDataType::FIXED_LEN_BYTE_ARRAY,
      _ => TParquetDataType(i)
    }
  }
}

impl From<&i32> for TParquetDataType {
  fn from(i: &i32) -> Self {
    TParquetDataType::from(*i)
  }
}

impl From<TParquetDataType> for i32 {
  fn from(e: TParquetDataType) -> i32 {
    e.0
  }
}

impl From<&TParquetDataType> for i32 {
  fn from(e: &TParquetDataType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetDataLogicalType(pub i32);

impl TParquetDataLogicalType {
  pub const UNDEFINED: TParquetDataLogicalType = TParquetDataLogicalType(0);
  pub const STRING: TParquetDataLogicalType = TParquetDataLogicalType(1);
  pub const MAP: TParquetDataLogicalType = TParquetDataLogicalType(2);
  pub const LIST: TParquetDataLogicalType = TParquetDataLogicalType(3);
  pub const ENUM: TParquetDataLogicalType = TParquetDataLogicalType(4);
  pub const DECIMAL: TParquetDataLogicalType = TParquetDataLogicalType(5);
  pub const DATE: TParquetDataLogicalType = TParquetDataLogicalType(6);
  pub const TIME: TParquetDataLogicalType = TParquetDataLogicalType(7);
  pub const TIMESTAMP: TParquetDataLogicalType = TParquetDataLogicalType(8);
  pub const INTERVAL: TParquetDataLogicalType = TParquetDataLogicalType(9);
  pub const INT: TParquetDataLogicalType = TParquetDataLogicalType(10);
  pub const NIL: TParquetDataLogicalType = TParquetDataLogicalType(11);
  pub const JSON: TParquetDataLogicalType = TParquetDataLogicalType(12);
  pub const BSON: TParquetDataLogicalType = TParquetDataLogicalType(13);
  pub const UUID: TParquetDataLogicalType = TParquetDataLogicalType(14);
  pub const NONE: TParquetDataLogicalType = TParquetDataLogicalType(15);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::UNDEFINED,
    Self::STRING,
    Self::MAP,
    Self::LIST,
    Self::ENUM,
    Self::DECIMAL,
    Self::DATE,
    Self::TIME,
    Self::TIMESTAMP,
    Self::INTERVAL,
    Self::INT,
    Self::NIL,
    Self::JSON,
    Self::BSON,
    Self::UUID,
    Self::NONE,
  ];
}

impl TSerializable for TParquetDataLogicalType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetDataLogicalType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TParquetDataLogicalType::from(enum_value))
  }
}

impl From<i32> for TParquetDataLogicalType {
  fn from(i: i32) -> Self {
    match i {
      0 => TParquetDataLogicalType::UNDEFINED,
      1 => TParquetDataLogicalType::STRING,
      2 => TParquetDataLogicalType::MAP,
      3 => TParquetDataLogicalType::LIST,
      4 => TParquetDataLogicalType::ENUM,
      5 => TParquetDataLogicalType::DECIMAL,
      6 => TParquetDataLogicalType::DATE,
      7 => TParquetDataLogicalType::TIME,
      8 => TParquetDataLogicalType::TIMESTAMP,
      9 => TParquetDataLogicalType::INTERVAL,
      10 => TParquetDataLogicalType::INT,
      11 => TParquetDataLogicalType::NIL,
      12 => TParquetDataLogicalType::JSON,
      13 => TParquetDataLogicalType::BSON,
      14 => TParquetDataLogicalType::UUID,
      15 => TParquetDataLogicalType::NONE,
      _ => TParquetDataLogicalType(i)
    }
  }
}

impl From<&i32> for TParquetDataLogicalType {
  fn from(i: &i32) -> Self {
    TParquetDataLogicalType::from(*i)
  }
}

impl From<TParquetDataLogicalType> for i32 {
  fn from(e: TParquetDataLogicalType) -> i32 {
    e.0
  }
}

impl From<&TParquetDataLogicalType> for i32 {
  fn from(e: &TParquetDataLogicalType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetRepetitionType(pub i32);

impl TParquetRepetitionType {
  pub const REQUIRED: TParquetRepetitionType = TParquetRepetitionType(0);
  pub const REPEATED: TParquetRepetitionType = TParquetRepetitionType(1);
  pub const OPTIONAL: TParquetRepetitionType = TParquetRepetitionType(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::REQUIRED,
    Self::REPEATED,
    Self::OPTIONAL,
  ];
}

impl TSerializable for TParquetRepetitionType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetRepetitionType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TParquetRepetitionType::from(enum_value))
  }
}

impl From<i32> for TParquetRepetitionType {
  fn from(i: i32) -> Self {
    match i {
      0 => TParquetRepetitionType::REQUIRED,
      1 => TParquetRepetitionType::REPEATED,
      2 => TParquetRepetitionType::OPTIONAL,
      _ => TParquetRepetitionType(i)
    }
  }
}

impl From<&i32> for TParquetRepetitionType {
  fn from(i: &i32) -> Self {
    TParquetRepetitionType::from(*i)
  }
}

impl From<TParquetRepetitionType> for i32 {
  fn from(e: TParquetRepetitionType) -> i32 {
    e.0
  }
}

impl From<&TParquetRepetitionType> for i32 {
  fn from(e: &TParquetRepetitionType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TGroupCommitMode(pub i32);

impl TGroupCommitMode {
  pub const SYNC_MODE: TGroupCommitMode = TGroupCommitMode(0);
  pub const ASYNC_MODE: TGroupCommitMode = TGroupCommitMode(1);
  pub const OFF_MODE: TGroupCommitMode = TGroupCommitMode(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::SYNC_MODE,
    Self::ASYNC_MODE,
    Self::OFF_MODE,
  ];
}

impl TSerializable for TGroupCommitMode {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TGroupCommitMode> {
    let enum_value = i_prot.read_i32()?;
    Ok(TGroupCommitMode::from(enum_value))
  }
}

impl From<i32> for TGroupCommitMode {
  fn from(i: i32) -> Self {
    match i {
      0 => TGroupCommitMode::SYNC_MODE,
      1 => TGroupCommitMode::ASYNC_MODE,
      2 => TGroupCommitMode::OFF_MODE,
      _ => TGroupCommitMode(i)
    }
  }
}

impl From<&i32> for TGroupCommitMode {
  fn from(i: &i32) -> Self {
    TGroupCommitMode::from(*i)
  }
}

impl From<TGroupCommitMode> for i32 {
  fn from(e: TGroupCommitMode) -> i32 {
    e.0
  }
}

impl From<&TGroupCommitMode> for i32 {
  fn from(e: &TGroupCommitMode) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveColumnType(pub i32);

impl THiveColumnType {
  pub const PARTITION_KEY: THiveColumnType = THiveColumnType(0);
  pub const REGULAR: THiveColumnType = THiveColumnType(1);
  pub const SYNTHESIZED: THiveColumnType = THiveColumnType(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::PARTITION_KEY,
    Self::REGULAR,
    Self::SYNTHESIZED,
  ];
}

impl TSerializable for THiveColumnType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveColumnType> {
    let enum_value = i_prot.read_i32()?;
    Ok(THiveColumnType::from(enum_value))
  }
}

impl From<i32> for THiveColumnType {
  fn from(i: i32) -> Self {
    match i {
      0 => THiveColumnType::PARTITION_KEY,
      1 => THiveColumnType::REGULAR,
      2 => THiveColumnType::SYNTHESIZED,
      _ => THiveColumnType(i)
    }
  }
}

impl From<&i32> for THiveColumnType {
  fn from(i: &i32) -> Self {
    THiveColumnType::from(*i)
  }
}

impl From<THiveColumnType> for i32 {
  fn from(e: THiveColumnType) -> i32 {
    e.0
  }
}

impl From<&THiveColumnType> for i32 {
  fn from(e: &THiveColumnType) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TUpdateMode(pub i32);

impl TUpdateMode {
  pub const NEW: TUpdateMode = TUpdateMode(0);
  pub const APPEND: TUpdateMode = TUpdateMode(1);
  pub const OVERWRITE: TUpdateMode = TUpdateMode(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::NEW,
    Self::APPEND,
    Self::OVERWRITE,
  ];
}

impl TSerializable for TUpdateMode {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TUpdateMode> {
    let enum_value = i_prot.read_i32()?;
    Ok(TUpdateMode::from(enum_value))
  }
}

impl From<i32> for TUpdateMode {
  fn from(i: i32) -> Self {
    match i {
      0 => TUpdateMode::NEW,
      1 => TUpdateMode::APPEND,
      2 => TUpdateMode::OVERWRITE,
      _ => TUpdateMode(i)
    }
  }
}

impl From<&i32> for TUpdateMode {
  fn from(i: &i32) -> Self {
    TUpdateMode::from(*i)
  }
}

impl From<TUpdateMode> for i32 {
  fn from(e: TUpdateMode) -> i32 {
    e.0
  }
}

impl From<&TUpdateMode> for i32 {
  fn from(e: &TUpdateMode) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TFileContent(pub i32);

impl TFileContent {
  pub const DATA: TFileContent = TFileContent(0);
  pub const POSITION_DELETES: TFileContent = TFileContent(1);
  pub const EQUALITY_DELETES: TFileContent = TFileContent(2);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::DATA,
    Self::POSITION_DELETES,
    Self::EQUALITY_DELETES,
  ];
}

impl TSerializable for TFileContent {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TFileContent> {
    let enum_value = i_prot.read_i32()?;
    Ok(TFileContent::from(enum_value))
  }
}

impl From<i32> for TFileContent {
  fn from(i: i32) -> Self {
    match i {
      0 => TFileContent::DATA,
      1 => TFileContent::POSITION_DELETES,
      2 => TFileContent::EQUALITY_DELETES,
      _ => TFileContent(i)
    }
  }
}

impl From<&i32> for TFileContent {
  fn from(i: &i32) -> Self {
    TFileContent::from(*i)
  }
}

impl From<TFileContent> for i32 {
  fn from(e: TFileContent) -> i32 {
    e.0
  }
}

impl From<&TFileContent> for i32 {
  fn from(e: &TFileContent) -> i32 {
    e.0
  }
}

#[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TDictLayoutType(pub i32);

impl TDictLayoutType {
  pub const HASH_MAP: TDictLayoutType = TDictLayoutType(0);
  pub const IP_TRIE: TDictLayoutType = TDictLayoutType(1);
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::HASH_MAP,
    Self::IP_TRIE,
  ];
}

impl TSerializable for TDictLayoutType {
  #[allow(clippy::trivially_copy_pass_by_ref)]
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    o_prot.write_i32(self.0)
  }
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TDictLayoutType> {
    let enum_value = i_prot.read_i32()?;
    Ok(TDictLayoutType::from(enum_value))
  }
}

impl From<i32> for TDictLayoutType {
  fn from(i: i32) -> Self {
    match i {
      0 => TDictLayoutType::HASH_MAP,
      1 => TDictLayoutType::IP_TRIE,
      _ => TDictLayoutType(i)
    }
  }
}

impl From<&i32> for TDictLayoutType {
  fn from(i: &i32) -> Self {
    TDictLayoutType::from(*i)
  }
}

impl From<TDictLayoutType> for i32 {
  fn from(e: TDictLayoutType) -> i32 {
    e.0
  }
}

impl From<&TDictLayoutType> for i32 {
  fn from(e: &TDictLayoutType) -> i32 {
    e.0
  }
}

//
// TParquetSchema
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TParquetSchema {
  pub schema_repetition_type: Option<TParquetRepetitionType>,
  pub schema_data_type: Option<TParquetDataType>,
  pub schema_column_name: Option<String>,
  pub schema_data_logical_type: Option<TParquetDataLogicalType>,
}

impl TParquetSchema {
  pub fn new<F1, F2, F3, F4>(schema_repetition_type: F1, schema_data_type: F2, schema_column_name: F3, schema_data_logical_type: F4) -> TParquetSchema where F1: Into<Option<TParquetRepetitionType>>, F2: Into<Option<TParquetDataType>>, F3: Into<Option<String>>, F4: Into<Option<TParquetDataLogicalType>> {
    TParquetSchema {
      schema_repetition_type: schema_repetition_type.into(),
      schema_data_type: schema_data_type.into(),
      schema_column_name: schema_column_name.into(),
      schema_data_logical_type: schema_data_logical_type.into(),
    }
  }
}

impl TSerializable for TParquetSchema {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TParquetSchema> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<TParquetRepetitionType> = None;
    let mut f_2: Option<TParquetDataType> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<TParquetDataLogicalType> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = TParquetRepetitionType::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = TParquetDataType::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = TParquetDataLogicalType::read_from_in_protocol(i_prot)?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TParquetSchema {
      schema_repetition_type: f_1,
      schema_data_type: f_2,
      schema_column_name: f_3,
      schema_data_logical_type: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TParquetSchema");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.schema_repetition_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema_repetition_type", TType::I32, 1))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.schema_data_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema_data_type", TType::I32, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.schema_column_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema_column_name", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.schema_data_logical_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema_data_logical_type", TType::I32, 4))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TResultFileSinkOptions
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TResultFileSinkOptions {
  pub file_path: String,
  pub file_format: plan_nodes::TFileFormatType,
  pub column_separator: Option<String>,
  pub line_delimiter: Option<String>,
  pub max_file_size_bytes: Option<i64>,
  pub broker_addresses: Option<Vec<types::TNetworkAddress>>,
  pub broker_properties: Option<BTreeMap<String, String>>,
  pub success_file_name: Option<String>,
  pub schema: Option<Vec<Vec<String>>>,
  pub file_properties: Option<BTreeMap<String, String>>,
  pub parquet_schemas: Option<Vec<TParquetSchema>>,
  pub parquet_compression_type: Option<TParquetCompressionType>,
  pub parquet_disable_dictionary: Option<bool>,
  pub parquet_version: Option<TParquetVersion>,
  pub orc_schema: Option<String>,
  pub delete_existing_files: Option<bool>,
  pub file_suffix: Option<String>,
  pub with_bom: Option<bool>,
  pub orc_compression_type: Option<plan_nodes::TFileCompressType>,
  pub orc_writer_version: Option<i64>,
  pub enable_int96_timestamps: Option<bool>,
  pub compression_type: Option<plan_nodes::TFileCompressType>,
}

impl TResultFileSinkOptions {
  pub fn new<F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F17, F18, F19, F20, F21, F22>(file_path: String, file_format: plan_nodes::TFileFormatType, column_separator: F3, line_delimiter: F4, max_file_size_bytes: F5, broker_addresses: F6, broker_properties: F7, success_file_name: F8, schema: F9, file_properties: F10, parquet_schemas: F11, parquet_compression_type: F12, parquet_disable_dictionary: F13, parquet_version: F14, orc_schema: F15, delete_existing_files: F16, file_suffix: F17, with_bom: F18, orc_compression_type: F19, orc_writer_version: F20, enable_int96_timestamps: F21, compression_type: F22) -> TResultFileSinkOptions where F3: Into<Option<String>>, F4: Into<Option<String>>, F5: Into<Option<i64>>, F6: Into<Option<Vec<types::TNetworkAddress>>>, F7: Into<Option<BTreeMap<String, String>>>, F8: Into<Option<String>>, F9: Into<Option<Vec<Vec<String>>>>, F10: Into<Option<BTreeMap<String, String>>>, F11: Into<Option<Vec<TParquetSchema>>>, F12: Into<Option<TParquetCompressionType>>, F13: Into<Option<bool>>, F14: Into<Option<TParquetVersion>>, F15: Into<Option<String>>, F16: Into<Option<bool>>, F17: Into<Option<String>>, F18: Into<Option<bool>>, F19: Into<Option<plan_nodes::TFileCompressType>>, F20: Into<Option<i64>>, F21: Into<Option<bool>>, F22: Into<Option<plan_nodes::TFileCompressType>> {
    TResultFileSinkOptions {
      file_path,
      file_format,
      column_separator: column_separator.into(),
      line_delimiter: line_delimiter.into(),
      max_file_size_bytes: max_file_size_bytes.into(),
      broker_addresses: broker_addresses.into(),
      broker_properties: broker_properties.into(),
      success_file_name: success_file_name.into(),
      schema: schema.into(),
      file_properties: file_properties.into(),
      parquet_schemas: parquet_schemas.into(),
      parquet_compression_type: parquet_compression_type.into(),
      parquet_disable_dictionary: parquet_disable_dictionary.into(),
      parquet_version: parquet_version.into(),
      orc_schema: orc_schema.into(),
      delete_existing_files: delete_existing_files.into(),
      file_suffix: file_suffix.into(),
      with_bom: with_bom.into(),
      orc_compression_type: orc_compression_type.into(),
      orc_writer_version: orc_writer_version.into(),
      enable_int96_timestamps: enable_int96_timestamps.into(),
      compression_type: compression_type.into(),
    }
  }
}

impl TSerializable for TResultFileSinkOptions {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TResultFileSinkOptions> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<plan_nodes::TFileFormatType> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<String> = None;
    let mut f_5: Option<i64> = None;
    let mut f_6: Option<Vec<types::TNetworkAddress>> = None;
    let mut f_7: Option<BTreeMap<String, String>> = None;
    let mut f_8: Option<String> = None;
    let mut f_9: Option<Vec<Vec<String>>> = None;
    let mut f_10: Option<BTreeMap<String, String>> = None;
    let mut f_11: Option<Vec<TParquetSchema>> = None;
    let mut f_12: Option<TParquetCompressionType> = None;
    let mut f_13: Option<bool> = None;
    let mut f_14: Option<TParquetVersion> = None;
    let mut f_15: Option<String> = None;
    let mut f_16: Option<bool> = None;
    let mut f_17: Option<String> = None;
    let mut f_18: Option<bool> = None;
    let mut f_19: Option<plan_nodes::TFileCompressType> = None;
    let mut f_20: Option<i64> = None;
    let mut f_21: Option<bool> = None;
    let mut f_22: Option<plan_nodes::TFileCompressType> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = plan_nodes::TFileFormatType::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_i64()?;
          f_5 = Some(val);
        },
        6 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<types::TNetworkAddress> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_0 = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
            val.push(list_elem_0);
          }
          i_prot.read_list_end()?;
          f_6 = Some(val);
        },
        7 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<String, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_1 = i_prot.read_string()?;
            let map_val_2 = i_prot.read_string()?;
            val.insert(map_key_1, map_val_2);
          }
          i_prot.read_map_end()?;
          f_7 = Some(val);
        },
        8 => {
          let val = i_prot.read_string()?;
          f_8 = Some(val);
        },
        9 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<Vec<String>> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_ident = i_prot.read_list_begin()?;
            let mut list_elem_3: Vec<String> = Vec::with_capacity(list_ident.size as usize);
            for _ in 0..list_ident.size {
              let list_elem_4 = i_prot.read_string()?;
              list_elem_3.push(list_elem_4);
            }
            i_prot.read_list_end()?;
            val.push(list_elem_3);
          }
          i_prot.read_list_end()?;
          f_9 = Some(val);
        },
        10 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<String, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_5 = i_prot.read_string()?;
            let map_val_6 = i_prot.read_string()?;
            val.insert(map_key_5, map_val_6);
          }
          i_prot.read_map_end()?;
          f_10 = Some(val);
        },
        11 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<TParquetSchema> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_7 = TParquetSchema::read_from_in_protocol(i_prot)?;
            val.push(list_elem_7);
          }
          i_prot.read_list_end()?;
          f_11 = Some(val);
        },
        12 => {
          let val = TParquetCompressionType::read_from_in_protocol(i_prot)?;
          f_12 = Some(val);
        },
        13 => {
          let val = i_prot.read_bool()?;
          f_13 = Some(val);
        },
        14 => {
          let val = TParquetVersion::read_from_in_protocol(i_prot)?;
          f_14 = Some(val);
        },
        15 => {
          let val = i_prot.read_string()?;
          f_15 = Some(val);
        },
        16 => {
          let val = i_prot.read_bool()?;
          f_16 = Some(val);
        },
        17 => {
          let val = i_prot.read_string()?;
          f_17 = Some(val);
        },
        18 => {
          let val = i_prot.read_bool()?;
          f_18 = Some(val);
        },
        19 => {
          let val = plan_nodes::TFileCompressType::read_from_in_protocol(i_prot)?;
          f_19 = Some(val);
        },
        20 => {
          let val = i_prot.read_i64()?;
          f_20 = Some(val);
        },
        21 => {
          let val = i_prot.read_bool()?;
          f_21 = Some(val);
        },
        22 => {
          let val = plan_nodes::TFileCompressType::read_from_in_protocol(i_prot)?;
          f_22 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TResultFileSinkOptions.file_path", &f_1)?;
    verify_required_field_exists("TResultFileSinkOptions.file_format", &f_2)?;
    let ret = TResultFileSinkOptions {
      file_path: f_1.expect("auto-generated code should have checked for presence of required fields"),
      file_format: f_2.expect("auto-generated code should have checked for presence of required fields"),
      column_separator: f_3,
      line_delimiter: f_4,
      max_file_size_bytes: f_5,
      broker_addresses: f_6,
      broker_properties: f_7,
      success_file_name: f_8,
      schema: f_9,
      file_properties: f_10,
      parquet_schemas: f_11,
      parquet_compression_type: f_12,
      parquet_disable_dictionary: f_13,
      parquet_version: f_14,
      orc_schema: f_15,
      delete_existing_files: f_16,
      file_suffix: f_17,
      with_bom: f_18,
      orc_compression_type: f_19,
      orc_writer_version: f_20,
      enable_int96_timestamps: f_21,
      compression_type: f_22,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TResultFileSinkOptions");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("file_path", TType::String, 1))?;
    o_prot.write_string(&self.file_path)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("file_format", TType::I32, 2))?;
    self.file_format.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    if let Some(ref fld_var) = self.column_separator {
      o_prot.write_field_begin(&TFieldIdentifier::new("column_separator", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.line_delimiter {
      o_prot.write_field_begin(&TFieldIdentifier::new("line_delimiter", TType::String, 4))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.max_file_size_bytes {
      o_prot.write_field_begin(&TFieldIdentifier::new("max_file_size_bytes", TType::I64, 5))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.broker_addresses {
      o_prot.write_field_begin(&TFieldIdentifier::new("broker_addresses", TType::List, 6))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.broker_properties {
      o_prot.write_field_begin(&TFieldIdentifier::new("broker_properties", TType::Map, 7))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::String, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_string(k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.success_file_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("success_file_name", TType::String, 8))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.schema {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema", TType::List, 9))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::List, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_list_begin(&TListIdentifier::new(TType::String, e.len() as i32))?;
        for e in e {
          o_prot.write_string(e)?;
        }
        o_prot.write_list_end()?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_properties {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_properties", TType::Map, 10))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::String, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_string(k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.parquet_schemas {
      o_prot.write_field_begin(&TFieldIdentifier::new("parquet_schemas", TType::List, 11))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.parquet_compression_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("parquet_compression_type", TType::I32, 12))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.parquet_disable_dictionary {
      o_prot.write_field_begin(&TFieldIdentifier::new("parquet_disable_dictionary", TType::Bool, 13))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.parquet_version {
      o_prot.write_field_begin(&TFieldIdentifier::new("parquet_version", TType::I32, 14))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.orc_schema {
      o_prot.write_field_begin(&TFieldIdentifier::new("orc_schema", TType::String, 15))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.delete_existing_files {
      o_prot.write_field_begin(&TFieldIdentifier::new("delete_existing_files", TType::Bool, 16))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_suffix {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_suffix", TType::String, 17))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.with_bom {
      o_prot.write_field_begin(&TFieldIdentifier::new("with_bom", TType::Bool, 18))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.orc_compression_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("orc_compression_type", TType::I32, 19))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.orc_writer_version {
      o_prot.write_field_begin(&TFieldIdentifier::new("orc_writer_version", TType::I64, 20))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.enable_int96_timestamps {
      o_prot.write_field_begin(&TFieldIdentifier::new("enable_int96_timestamps", TType::Bool, 21))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.compression_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("compression_type", TType::I32, 22))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TMemoryScratchSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TMemoryScratchSink {
}

impl TMemoryScratchSink {
  pub fn new() -> TMemoryScratchSink {
    TMemoryScratchSink {}
  }
}

impl TSerializable for TMemoryScratchSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TMemoryScratchSink> {
    i_prot.read_struct_begin()?;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      i_prot.skip(field_ident.field_type)?;
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TMemoryScratchSink {};
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TMemoryScratchSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TPlanFragmentDestination
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TPlanFragmentDestination {
  pub fragment_instance_id: types::TUniqueId,
  pub server: types::TNetworkAddress,
  pub brpc_server: Option<types::TNetworkAddress>,
}

impl TPlanFragmentDestination {
  pub fn new<F3>(fragment_instance_id: types::TUniqueId, server: types::TNetworkAddress, brpc_server: F3) -> TPlanFragmentDestination where F3: Into<Option<types::TNetworkAddress>> {
    TPlanFragmentDestination {
      fragment_instance_id,
      server,
      brpc_server: brpc_server.into(),
    }
  }
}

impl TSerializable for TPlanFragmentDestination {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TPlanFragmentDestination> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<types::TUniqueId> = None;
    let mut f_2: Option<types::TNetworkAddress> = None;
    let mut f_3: Option<types::TNetworkAddress> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = types::TUniqueId::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TPlanFragmentDestination.fragment_instance_id", &f_1)?;
    verify_required_field_exists("TPlanFragmentDestination.server", &f_2)?;
    let ret = TPlanFragmentDestination {
      fragment_instance_id: f_1.expect("auto-generated code should have checked for presence of required fields"),
      server: f_2.expect("auto-generated code should have checked for presence of required fields"),
      brpc_server: f_3,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TPlanFragmentDestination");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("fragment_instance_id", TType::Struct, 1))?;
    self.fragment_instance_id.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("server", TType::Struct, 2))?;
    self.server.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    if let Some(ref fld_var) = self.brpc_server {
      o_prot.write_field_begin(&TFieldIdentifier::new("brpc_server", TType::Struct, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TDataStreamSink
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TDataStreamSink {
  pub dest_node_id: types::TPlanNodeId,
  pub output_partition: partitions::TDataPartition,
  pub ignore_not_found: Option<bool>,
  pub output_exprs: Option<Vec<exprs::TExpr>>,
  pub output_tuple_id: Option<types::TTupleId>,
  pub conjuncts: Option<Vec<exprs::TExpr>>,
  pub runtime_filters: Option<Vec<plan_nodes::TRuntimeFilterDesc>>,
  pub tablet_sink_schema: Option<descriptors::TOlapTableSchemaParam>,
  pub tablet_sink_partition: Option<descriptors::TOlapTablePartitionParam>,
  pub tablet_sink_location: Option<descriptors::TOlapTableLocationParam>,
  pub tablet_sink_txn_id: Option<i64>,
  pub tablet_sink_tuple_id: Option<types::TTupleId>,
  pub tablet_sink_exprs: Option<Vec<exprs::TExpr>>,
  pub is_merge: Option<bool>,
}

impl TDataStreamSink {
  pub fn new<F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14>(dest_node_id: types::TPlanNodeId, output_partition: partitions::TDataPartition, ignore_not_found: F3, output_exprs: F4, output_tuple_id: F5, conjuncts: F6, runtime_filters: F7, tablet_sink_schema: F8, tablet_sink_partition: F9, tablet_sink_location: F10, tablet_sink_txn_id: F11, tablet_sink_tuple_id: F12, tablet_sink_exprs: F13, is_merge: F14) -> TDataStreamSink where F3: Into<Option<bool>>, F4: Into<Option<Vec<exprs::TExpr>>>, F5: Into<Option<types::TTupleId>>, F6: Into<Option<Vec<exprs::TExpr>>>, F7: Into<Option<Vec<plan_nodes::TRuntimeFilterDesc>>>, F8: Into<Option<descriptors::TOlapTableSchemaParam>>, F9: Into<Option<descriptors::TOlapTablePartitionParam>>, F10: Into<Option<descriptors::TOlapTableLocationParam>>, F11: Into<Option<i64>>, F12: Into<Option<types::TTupleId>>, F13: Into<Option<Vec<exprs::TExpr>>>, F14: Into<Option<bool>> {
    TDataStreamSink {
      dest_node_id,
      output_partition,
      ignore_not_found: ignore_not_found.into(),
      output_exprs: output_exprs.into(),
      output_tuple_id: output_tuple_id.into(),
      conjuncts: conjuncts.into(),
      runtime_filters: runtime_filters.into(),
      tablet_sink_schema: tablet_sink_schema.into(),
      tablet_sink_partition: tablet_sink_partition.into(),
      tablet_sink_location: tablet_sink_location.into(),
      tablet_sink_txn_id: tablet_sink_txn_id.into(),
      tablet_sink_tuple_id: tablet_sink_tuple_id.into(),
      tablet_sink_exprs: tablet_sink_exprs.into(),
      is_merge: is_merge.into(),
    }
  }
}

impl TSerializable for TDataStreamSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TDataStreamSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<types::TPlanNodeId> = None;
    let mut f_2: Option<partitions::TDataPartition> = None;
    let mut f_3: Option<bool> = None;
    let mut f_4: Option<Vec<exprs::TExpr>> = None;
    let mut f_5: Option<types::TTupleId> = None;
    let mut f_6: Option<Vec<exprs::TExpr>> = None;
    let mut f_7: Option<Vec<plan_nodes::TRuntimeFilterDesc>> = None;
    let mut f_8: Option<descriptors::TOlapTableSchemaParam> = None;
    let mut f_9: Option<descriptors::TOlapTablePartitionParam> = None;
    let mut f_10: Option<descriptors::TOlapTableLocationParam> = None;
    let mut f_11: Option<i64> = None;
    let mut f_12: Option<types::TTupleId> = None;
    let mut f_13: Option<Vec<exprs::TExpr>> = None;
    let mut f_14: Option<bool> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_i32()?;
          f_1 = Some(val);
        },
        2 => {
          let val = partitions::TDataPartition::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_bool()?;
          f_3 = Some(val);
        },
        4 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<exprs::TExpr> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_8 = exprs::TExpr::read_from_in_protocol(i_prot)?;
            val.push(list_elem_8);
          }
          i_prot.read_list_end()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_i32()?;
          f_5 = Some(val);
        },
        6 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<exprs::TExpr> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_9 = exprs::TExpr::read_from_in_protocol(i_prot)?;
            val.push(list_elem_9);
          }
          i_prot.read_list_end()?;
          f_6 = Some(val);
        },
        7 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<plan_nodes::TRuntimeFilterDesc> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_10 = plan_nodes::TRuntimeFilterDesc::read_from_in_protocol(i_prot)?;
            val.push(list_elem_10);
          }
          i_prot.read_list_end()?;
          f_7 = Some(val);
        },
        8 => {
          let val = descriptors::TOlapTableSchemaParam::read_from_in_protocol(i_prot)?;
          f_8 = Some(val);
        },
        9 => {
          let val = descriptors::TOlapTablePartitionParam::read_from_in_protocol(i_prot)?;
          f_9 = Some(val);
        },
        10 => {
          let val = descriptors::TOlapTableLocationParam::read_from_in_protocol(i_prot)?;
          f_10 = Some(val);
        },
        11 => {
          let val = i_prot.read_i64()?;
          f_11 = Some(val);
        },
        12 => {
          let val = i_prot.read_i32()?;
          f_12 = Some(val);
        },
        13 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<exprs::TExpr> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_11 = exprs::TExpr::read_from_in_protocol(i_prot)?;
            val.push(list_elem_11);
          }
          i_prot.read_list_end()?;
          f_13 = Some(val);
        },
        14 => {
          let val = i_prot.read_bool()?;
          f_14 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TDataStreamSink.dest_node_id", &f_1)?;
    verify_required_field_exists("TDataStreamSink.output_partition", &f_2)?;
    let ret = TDataStreamSink {
      dest_node_id: f_1.expect("auto-generated code should have checked for presence of required fields"),
      output_partition: f_2.expect("auto-generated code should have checked for presence of required fields"),
      ignore_not_found: f_3,
      output_exprs: f_4,
      output_tuple_id: f_5,
      conjuncts: f_6,
      runtime_filters: f_7,
      tablet_sink_schema: f_8,
      tablet_sink_partition: f_9,
      tablet_sink_location: f_10,
      tablet_sink_txn_id: f_11,
      tablet_sink_tuple_id: f_12,
      tablet_sink_exprs: f_13,
      is_merge: f_14,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TDataStreamSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("dest_node_id", TType::I32, 1))?;
    o_prot.write_i32(self.dest_node_id)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("output_partition", TType::Struct, 2))?;
    self.output_partition.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    if let Some(fld_var) = self.ignore_not_found {
      o_prot.write_field_begin(&TFieldIdentifier::new("ignore_not_found", TType::Bool, 3))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.output_exprs {
      o_prot.write_field_begin(&TFieldIdentifier::new("output_exprs", TType::List, 4))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.output_tuple_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("output_tuple_id", TType::I32, 5))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.conjuncts {
      o_prot.write_field_begin(&TFieldIdentifier::new("conjuncts", TType::List, 6))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.runtime_filters {
      o_prot.write_field_begin(&TFieldIdentifier::new("runtime_filters", TType::List, 7))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.tablet_sink_schema {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_schema", TType::Struct, 8))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.tablet_sink_partition {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_partition", TType::Struct, 9))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.tablet_sink_location {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_location", TType::Struct, 10))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.tablet_sink_txn_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_txn_id", TType::I64, 11))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.tablet_sink_tuple_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_tuple_id", TType::I32, 12))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.tablet_sink_exprs {
      o_prot.write_field_begin(&TFieldIdentifier::new("tablet_sink_exprs", TType::List, 13))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.is_merge {
      o_prot.write_field_begin(&TFieldIdentifier::new("is_merge", TType::Bool, 14))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TMultiCastDataStreamSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TMultiCastDataStreamSink {
  pub sinks: Option<Vec<TDataStreamSink>>,
  pub destinations: Option<Vec<Vec<TPlanFragmentDestination>>>,
}

impl TMultiCastDataStreamSink {
  pub fn new<F1, F2>(sinks: F1, destinations: F2) -> TMultiCastDataStreamSink where F1: Into<Option<Vec<TDataStreamSink>>>, F2: Into<Option<Vec<Vec<TPlanFragmentDestination>>>> {
    TMultiCastDataStreamSink {
      sinks: sinks.into(),
      destinations: destinations.into(),
    }
  }
}

impl TSerializable for TMultiCastDataStreamSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TMultiCastDataStreamSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<Vec<TDataStreamSink>> = None;
    let mut f_2: Option<Vec<Vec<TPlanFragmentDestination>>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<TDataStreamSink> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_12 = TDataStreamSink::read_from_in_protocol(i_prot)?;
            val.push(list_elem_12);
          }
          i_prot.read_list_end()?;
          f_1 = Some(val);
        },
        2 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<Vec<TPlanFragmentDestination>> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_ident = i_prot.read_list_begin()?;
            let mut list_elem_13: Vec<TPlanFragmentDestination> = Vec::with_capacity(list_ident.size as usize);
            for _ in 0..list_ident.size {
              let list_elem_14 = TPlanFragmentDestination::read_from_in_protocol(i_prot)?;
              list_elem_13.push(list_elem_14);
            }
            i_prot.read_list_end()?;
            val.push(list_elem_13);
          }
          i_prot.read_list_end()?;
          f_2 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TMultiCastDataStreamSink {
      sinks: f_1,
      destinations: f_2,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TMultiCastDataStreamSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.sinks {
      o_prot.write_field_begin(&TFieldIdentifier::new("sinks", TType::List, 1))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.destinations {
      o_prot.write_field_begin(&TFieldIdentifier::new("destinations", TType::List, 2))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::List, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, e.len() as i32))?;
        for e in e {
          e.write_to_out_protocol(o_prot)?;
        }
        o_prot.write_list_end()?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TFetchOption
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TFetchOption {
  pub use_two_phase_fetch: Option<bool>,
  pub nodes_info: Option<descriptors::TPaloNodesInfo>,
  pub fetch_row_store: Option<bool>,
  pub column_desc: Option<Vec<descriptors::TColumn>>,
}

impl TFetchOption {
  pub fn new<F1, F2, F3, F4>(use_two_phase_fetch: F1, nodes_info: F2, fetch_row_store: F3, column_desc: F4) -> TFetchOption where F1: Into<Option<bool>>, F2: Into<Option<descriptors::TPaloNodesInfo>>, F3: Into<Option<bool>>, F4: Into<Option<Vec<descriptors::TColumn>>> {
    TFetchOption {
      use_two_phase_fetch: use_two_phase_fetch.into(),
      nodes_info: nodes_info.into(),
      fetch_row_store: fetch_row_store.into(),
      column_desc: column_desc.into(),
    }
  }
}

impl TSerializable for TFetchOption {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TFetchOption> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<bool> = None;
    let mut f_2: Option<descriptors::TPaloNodesInfo> = None;
    let mut f_3: Option<bool> = None;
    let mut f_4: Option<Vec<descriptors::TColumn>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_bool()?;
          f_1 = Some(val);
        },
        2 => {
          let val = descriptors::TPaloNodesInfo::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_bool()?;
          f_3 = Some(val);
        },
        4 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<descriptors::TColumn> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_15 = descriptors::TColumn::read_from_in_protocol(i_prot)?;
            val.push(list_elem_15);
          }
          i_prot.read_list_end()?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TFetchOption {
      use_two_phase_fetch: f_1,
      nodes_info: f_2,
      fetch_row_store: f_3,
      column_desc: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TFetchOption");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(fld_var) = self.use_two_phase_fetch {
      o_prot.write_field_begin(&TFieldIdentifier::new("use_two_phase_fetch", TType::Bool, 1))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.nodes_info {
      o_prot.write_field_begin(&TFieldIdentifier::new("nodes_info", TType::Struct, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.fetch_row_store {
      o_prot.write_field_begin(&TFieldIdentifier::new("fetch_row_store", TType::Bool, 3))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.column_desc {
      o_prot.write_field_begin(&TFieldIdentifier::new("column_desc", TType::List, 4))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TResultSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TResultSink {
  pub type_: Option<TResultSinkType>,
  pub file_options: Option<TResultFileSinkOptions>,
  pub fetch_option: Option<TFetchOption>,
}

impl TResultSink {
  pub fn new<F1, F2, F3>(type_: F1, file_options: F2, fetch_option: F3) -> TResultSink where F1: Into<Option<TResultSinkType>>, F2: Into<Option<TResultFileSinkOptions>>, F3: Into<Option<TFetchOption>> {
    TResultSink {
      type_: type_.into(),
      file_options: file_options.into(),
      fetch_option: fetch_option.into(),
    }
  }
}

impl TSerializable for TResultSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TResultSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<TResultSinkType> = None;
    let mut f_2: Option<TResultFileSinkOptions> = None;
    let mut f_3: Option<TFetchOption> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = TResultSinkType::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = TResultFileSinkOptions::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = TFetchOption::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TResultSink {
      type_: f_1,
      file_options: f_2,
      fetch_option: f_3,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TResultSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.type_ {
      o_prot.write_field_begin(&TFieldIdentifier::new("type", TType::I32, 1))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_options {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_options", TType::Struct, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.fetch_option {
      o_prot.write_field_begin(&TFieldIdentifier::new("fetch_option", TType::Struct, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TResultFileSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TResultFileSink {
  pub file_options: Option<TResultFileSinkOptions>,
  pub storage_backend_type: Option<types::TStorageBackendType>,
  pub dest_node_id: Option<types::TPlanNodeId>,
  pub output_tuple_id: Option<types::TTupleId>,
  pub header: Option<String>,
  pub header_type: Option<String>,
}

impl TResultFileSink {
  pub fn new<F1, F2, F3, F4, F5, F6>(file_options: F1, storage_backend_type: F2, dest_node_id: F3, output_tuple_id: F4, header: F5, header_type: F6) -> TResultFileSink where F1: Into<Option<TResultFileSinkOptions>>, F2: Into<Option<types::TStorageBackendType>>, F3: Into<Option<types::TPlanNodeId>>, F4: Into<Option<types::TTupleId>>, F5: Into<Option<String>>, F6: Into<Option<String>> {
    TResultFileSink {
      file_options: file_options.into(),
      storage_backend_type: storage_backend_type.into(),
      dest_node_id: dest_node_id.into(),
      output_tuple_id: output_tuple_id.into(),
      header: header.into(),
      header_type: header_type.into(),
    }
  }
}

impl TSerializable for TResultFileSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TResultFileSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<TResultFileSinkOptions> = None;
    let mut f_2: Option<types::TStorageBackendType> = None;
    let mut f_3: Option<types::TPlanNodeId> = None;
    let mut f_4: Option<types::TTupleId> = None;
    let mut f_5: Option<String> = None;
    let mut f_6: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = TResultFileSinkOptions::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = types::TStorageBackendType::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_i32()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_i32()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_string()?;
          f_5 = Some(val);
        },
        6 => {
          let val = i_prot.read_string()?;
          f_6 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TResultFileSink {
      file_options: f_1,
      storage_backend_type: f_2,
      dest_node_id: f_3,
      output_tuple_id: f_4,
      header: f_5,
      header_type: f_6,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TResultFileSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.file_options {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_options", TType::Struct, 1))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.storage_backend_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("storage_backend_type", TType::I32, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.dest_node_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("dest_node_id", TType::I32, 3))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.output_tuple_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("output_tuple_id", TType::I32, 4))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.header {
      o_prot.write_field_begin(&TFieldIdentifier::new("header", TType::String, 5))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.header_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("header_type", TType::String, 6))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TMysqlTableSink
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TMysqlTableSink {
  pub host: String,
  pub port: i32,
  pub user: String,
  pub passwd: String,
  pub db: String,
  pub table: String,
  pub charset: String,
}

impl TMysqlTableSink {
  pub fn new(host: String, port: i32, user: String, passwd: String, db: String, table: String, charset: String) -> TMysqlTableSink {
    TMysqlTableSink {
      host,
      port,
      user,
      passwd,
      db,
      table,
      charset,
    }
  }
}

impl TSerializable for TMysqlTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TMysqlTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<i32> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<String> = None;
    let mut f_5: Option<String> = None;
    let mut f_6: Option<String> = None;
    let mut f_7: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_i32()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_string()?;
          f_5 = Some(val);
        },
        6 => {
          let val = i_prot.read_string()?;
          f_6 = Some(val);
        },
        7 => {
          let val = i_prot.read_string()?;
          f_7 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TMysqlTableSink.host", &f_1)?;
    verify_required_field_exists("TMysqlTableSink.port", &f_2)?;
    verify_required_field_exists("TMysqlTableSink.user", &f_3)?;
    verify_required_field_exists("TMysqlTableSink.passwd", &f_4)?;
    verify_required_field_exists("TMysqlTableSink.db", &f_5)?;
    verify_required_field_exists("TMysqlTableSink.table", &f_6)?;
    verify_required_field_exists("TMysqlTableSink.charset", &f_7)?;
    let ret = TMysqlTableSink {
      host: f_1.expect("auto-generated code should have checked for presence of required fields"),
      port: f_2.expect("auto-generated code should have checked for presence of required fields"),
      user: f_3.expect("auto-generated code should have checked for presence of required fields"),
      passwd: f_4.expect("auto-generated code should have checked for presence of required fields"),
      db: f_5.expect("auto-generated code should have checked for presence of required fields"),
      table: f_6.expect("auto-generated code should have checked for presence of required fields"),
      charset: f_7.expect("auto-generated code should have checked for presence of required fields"),
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TMysqlTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("host", TType::String, 1))?;
    o_prot.write_string(&self.host)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("port", TType::I32, 2))?;
    o_prot.write_i32(self.port)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("user", TType::String, 3))?;
    o_prot.write_string(&self.user)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("passwd", TType::String, 4))?;
    o_prot.write_string(&self.passwd)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("db", TType::String, 5))?;
    o_prot.write_string(&self.db)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("table", TType::String, 6))?;
    o_prot.write_string(&self.table)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("charset", TType::String, 7))?;
    o_prot.write_string(&self.charset)?;
    o_prot.write_field_end()?;
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TOdbcTableSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TOdbcTableSink {
  pub connect_string: Option<String>,
  pub table: Option<String>,
  pub use_transaction: Option<bool>,
}

impl TOdbcTableSink {
  pub fn new<F1, F2, F3>(connect_string: F1, table: F2, use_transaction: F3) -> TOdbcTableSink where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<bool>> {
    TOdbcTableSink {
      connect_string: connect_string.into(),
      table: table.into(),
      use_transaction: use_transaction.into(),
    }
  }
}

impl TSerializable for TOdbcTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TOdbcTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<bool> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_bool()?;
          f_3 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TOdbcTableSink {
      connect_string: f_1,
      table: f_2,
      use_transaction: f_3,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TOdbcTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.connect_string {
      o_prot.write_field_begin(&TFieldIdentifier::new("connect_string", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.table {
      o_prot.write_field_begin(&TFieldIdentifier::new("table", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.use_transaction {
      o_prot.write_field_begin(&TFieldIdentifier::new("use_transaction", TType::Bool, 3))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TJdbcTableSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TJdbcTableSink {
  pub jdbc_table: Option<descriptors::TJdbcTable>,
  pub use_transaction: Option<bool>,
  pub table_type: Option<types::TOdbcTableType>,
  pub insert_sql: Option<String>,
}

impl TJdbcTableSink {
  pub fn new<F1, F2, F3, F4>(jdbc_table: F1, use_transaction: F2, table_type: F3, insert_sql: F4) -> TJdbcTableSink where F1: Into<Option<descriptors::TJdbcTable>>, F2: Into<Option<bool>>, F3: Into<Option<types::TOdbcTableType>>, F4: Into<Option<String>> {
    TJdbcTableSink {
      jdbc_table: jdbc_table.into(),
      use_transaction: use_transaction.into(),
      table_type: table_type.into(),
      insert_sql: insert_sql.into(),
    }
  }
}

impl TSerializable for TJdbcTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TJdbcTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<descriptors::TJdbcTable> = None;
    let mut f_2: Option<bool> = None;
    let mut f_3: Option<types::TOdbcTableType> = None;
    let mut f_4: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = descriptors::TJdbcTable::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_bool()?;
          f_2 = Some(val);
        },
        3 => {
          let val = types::TOdbcTableType::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TJdbcTableSink {
      jdbc_table: f_1,
      use_transaction: f_2,
      table_type: f_3,
      insert_sql: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TJdbcTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.jdbc_table {
      o_prot.write_field_begin(&TFieldIdentifier::new("jdbc_table", TType::Struct, 1))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.use_transaction {
      o_prot.write_field_begin(&TFieldIdentifier::new("use_transaction", TType::Bool, 2))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.table_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("table_type", TType::I32, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.insert_sql {
      o_prot.write_field_begin(&TFieldIdentifier::new("insert_sql", TType::String, 4))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TExportSink
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TExportSink {
  pub file_type: types::TFileType,
  pub export_path: String,
  pub column_separator: String,
  pub line_delimiter: String,
  pub broker_addresses: Option<Vec<types::TNetworkAddress>>,
  pub properties: Option<BTreeMap<String, String>>,
  pub header: Option<String>,
}

impl TExportSink {
  pub fn new<F5, F6, F7>(file_type: types::TFileType, export_path: String, column_separator: String, line_delimiter: String, broker_addresses: F5, properties: F6, header: F7) -> TExportSink where F5: Into<Option<Vec<types::TNetworkAddress>>>, F6: Into<Option<BTreeMap<String, String>>>, F7: Into<Option<String>> {
    TExportSink {
      file_type,
      export_path,
      column_separator,
      line_delimiter,
      broker_addresses: broker_addresses.into(),
      properties: properties.into(),
      header: header.into(),
    }
  }
}

impl TSerializable for TExportSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TExportSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<types::TFileType> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<String> = None;
    let mut f_5: Option<Vec<types::TNetworkAddress>> = None;
    let mut f_6: Option<BTreeMap<String, String>> = None;
    let mut f_7: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = types::TFileType::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        5 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<types::TNetworkAddress> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_16 = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
            val.push(list_elem_16);
          }
          i_prot.read_list_end()?;
          f_5 = Some(val);
        },
        6 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<String, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_17 = i_prot.read_string()?;
            let map_val_18 = i_prot.read_string()?;
            val.insert(map_key_17, map_val_18);
          }
          i_prot.read_map_end()?;
          f_6 = Some(val);
        },
        7 => {
          let val = i_prot.read_string()?;
          f_7 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TExportSink.file_type", &f_1)?;
    verify_required_field_exists("TExportSink.export_path", &f_2)?;
    verify_required_field_exists("TExportSink.column_separator", &f_3)?;
    verify_required_field_exists("TExportSink.line_delimiter", &f_4)?;
    let ret = TExportSink {
      file_type: f_1.expect("auto-generated code should have checked for presence of required fields"),
      export_path: f_2.expect("auto-generated code should have checked for presence of required fields"),
      column_separator: f_3.expect("auto-generated code should have checked for presence of required fields"),
      line_delimiter: f_4.expect("auto-generated code should have checked for presence of required fields"),
      broker_addresses: f_5,
      properties: f_6,
      header: f_7,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TExportSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("file_type", TType::I32, 1))?;
    self.file_type.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("export_path", TType::String, 2))?;
    o_prot.write_string(&self.export_path)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("column_separator", TType::String, 3))?;
    o_prot.write_string(&self.column_separator)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("line_delimiter", TType::String, 4))?;
    o_prot.write_string(&self.line_delimiter)?;
    o_prot.write_field_end()?;
    if let Some(ref fld_var) = self.broker_addresses {
      o_prot.write_field_begin(&TFieldIdentifier::new("broker_addresses", TType::List, 5))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.properties {
      o_prot.write_field_begin(&TFieldIdentifier::new("properties", TType::Map, 6))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::String, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_string(k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.header {
      o_prot.write_field_begin(&TFieldIdentifier::new("header", TType::String, 7))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TOlapTableSink
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TOlapTableSink {
  pub load_id: types::TUniqueId,
  pub txn_id: i64,
  pub db_id: i64,
  pub table_id: i64,
  pub tuple_id: i32,
  pub num_replicas: i32,
  pub need_gen_rollup: bool,
  pub db_name: Option<String>,
  pub table_name: Option<String>,
  pub schema: descriptors::TOlapTableSchemaParam,
  pub partition: descriptors::TOlapTablePartitionParam,
  pub location: descriptors::TOlapTableLocationParam,
  pub nodes_info: descriptors::TPaloNodesInfo,
  pub load_channel_timeout_s: Option<i64>,
  pub send_batch_parallelism: Option<i32>,
  pub load_to_single_tablet: Option<bool>,
  pub write_single_replica: Option<bool>,
  pub slave_location: Option<descriptors::TOlapTableLocationParam>,
  pub txn_timeout_s: Option<i64>,
  pub write_file_cache: Option<bool>,
  pub base_schema_version: Option<i64>,
  pub group_commit_mode: Option<TGroupCommitMode>,
  pub max_filter_ratio: Option<OrderedFloat<f64>>,
  pub storage_vault_id: Option<String>,
}

impl TOlapTableSink {
  pub fn new<F8, F9, F14, F15, F16, F17, F18, F19, F20, F21, F22, F23, F24>(load_id: types::TUniqueId, txn_id: i64, db_id: i64, table_id: i64, tuple_id: i32, num_replicas: i32, need_gen_rollup: bool, db_name: F8, table_name: F9, schema: descriptors::TOlapTableSchemaParam, partition: descriptors::TOlapTablePartitionParam, location: descriptors::TOlapTableLocationParam, nodes_info: descriptors::TPaloNodesInfo, load_channel_timeout_s: F14, send_batch_parallelism: F15, load_to_single_tablet: F16, write_single_replica: F17, slave_location: F18, txn_timeout_s: F19, write_file_cache: F20, base_schema_version: F21, group_commit_mode: F22, max_filter_ratio: F23, storage_vault_id: F24) -> TOlapTableSink where F8: Into<Option<String>>, F9: Into<Option<String>>, F14: Into<Option<i64>>, F15: Into<Option<i32>>, F16: Into<Option<bool>>, F17: Into<Option<bool>>, F18: Into<Option<descriptors::TOlapTableLocationParam>>, F19: Into<Option<i64>>, F20: Into<Option<bool>>, F21: Into<Option<i64>>, F22: Into<Option<TGroupCommitMode>>, F23: Into<Option<OrderedFloat<f64>>>, F24: Into<Option<String>> {
    TOlapTableSink {
      load_id,
      txn_id,
      db_id,
      table_id,
      tuple_id,
      num_replicas,
      need_gen_rollup,
      db_name: db_name.into(),
      table_name: table_name.into(),
      schema,
      partition,
      location,
      nodes_info,
      load_channel_timeout_s: load_channel_timeout_s.into(),
      send_batch_parallelism: send_batch_parallelism.into(),
      load_to_single_tablet: load_to_single_tablet.into(),
      write_single_replica: write_single_replica.into(),
      slave_location: slave_location.into(),
      txn_timeout_s: txn_timeout_s.into(),
      write_file_cache: write_file_cache.into(),
      base_schema_version: base_schema_version.into(),
      group_commit_mode: group_commit_mode.into(),
      max_filter_ratio: max_filter_ratio.into(),
      storage_vault_id: storage_vault_id.into(),
    }
  }
}

impl TSerializable for TOlapTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TOlapTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<types::TUniqueId> = None;
    let mut f_2: Option<i64> = None;
    let mut f_3: Option<i64> = None;
    let mut f_4: Option<i64> = None;
    let mut f_5: Option<i32> = None;
    let mut f_6: Option<i32> = None;
    let mut f_7: Option<bool> = None;
    let mut f_8: Option<String> = None;
    let mut f_9: Option<String> = None;
    let mut f_10: Option<descriptors::TOlapTableSchemaParam> = None;
    let mut f_11: Option<descriptors::TOlapTablePartitionParam> = None;
    let mut f_12: Option<descriptors::TOlapTableLocationParam> = None;
    let mut f_13: Option<descriptors::TPaloNodesInfo> = None;
    let mut f_14: Option<i64> = None;
    let mut f_15: Option<i32> = None;
    let mut f_16: Option<bool> = None;
    let mut f_17: Option<bool> = None;
    let mut f_18: Option<descriptors::TOlapTableLocationParam> = None;
    let mut f_19: Option<i64> = None;
    let mut f_20: Option<bool> = None;
    let mut f_21: Option<i64> = None;
    let mut f_22: Option<TGroupCommitMode> = None;
    let mut f_23: Option<OrderedFloat<f64>> = None;
    let mut f_24: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = types::TUniqueId::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_i64()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_i64()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_i64()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_i32()?;
          f_5 = Some(val);
        },
        6 => {
          let val = i_prot.read_i32()?;
          f_6 = Some(val);
        },
        7 => {
          let val = i_prot.read_bool()?;
          f_7 = Some(val);
        },
        8 => {
          let val = i_prot.read_string()?;
          f_8 = Some(val);
        },
        9 => {
          let val = i_prot.read_string()?;
          f_9 = Some(val);
        },
        10 => {
          let val = descriptors::TOlapTableSchemaParam::read_from_in_protocol(i_prot)?;
          f_10 = Some(val);
        },
        11 => {
          let val = descriptors::TOlapTablePartitionParam::read_from_in_protocol(i_prot)?;
          f_11 = Some(val);
        },
        12 => {
          let val = descriptors::TOlapTableLocationParam::read_from_in_protocol(i_prot)?;
          f_12 = Some(val);
        },
        13 => {
          let val = descriptors::TPaloNodesInfo::read_from_in_protocol(i_prot)?;
          f_13 = Some(val);
        },
        14 => {
          let val = i_prot.read_i64()?;
          f_14 = Some(val);
        },
        15 => {
          let val = i_prot.read_i32()?;
          f_15 = Some(val);
        },
        16 => {
          let val = i_prot.read_bool()?;
          f_16 = Some(val);
        },
        17 => {
          let val = i_prot.read_bool()?;
          f_17 = Some(val);
        },
        18 => {
          let val = descriptors::TOlapTableLocationParam::read_from_in_protocol(i_prot)?;
          f_18 = Some(val);
        },
        19 => {
          let val = i_prot.read_i64()?;
          f_19 = Some(val);
        },
        20 => {
          let val = i_prot.read_bool()?;
          f_20 = Some(val);
        },
        21 => {
          let val = i_prot.read_i64()?;
          f_21 = Some(val);
        },
        22 => {
          let val = TGroupCommitMode::read_from_in_protocol(i_prot)?;
          f_22 = Some(val);
        },
        23 => {
          let val = OrderedFloat::from(i_prot.read_double()?);
          f_23 = Some(val);
        },
        24 => {
          let val = i_prot.read_string()?;
          f_24 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TOlapTableSink.load_id", &f_1)?;
    verify_required_field_exists("TOlapTableSink.txn_id", &f_2)?;
    verify_required_field_exists("TOlapTableSink.db_id", &f_3)?;
    verify_required_field_exists("TOlapTableSink.table_id", &f_4)?;
    verify_required_field_exists("TOlapTableSink.tuple_id", &f_5)?;
    verify_required_field_exists("TOlapTableSink.num_replicas", &f_6)?;
    verify_required_field_exists("TOlapTableSink.need_gen_rollup", &f_7)?;
    verify_required_field_exists("TOlapTableSink.schema", &f_10)?;
    verify_required_field_exists("TOlapTableSink.partition", &f_11)?;
    verify_required_field_exists("TOlapTableSink.location", &f_12)?;
    verify_required_field_exists("TOlapTableSink.nodes_info", &f_13)?;
    let ret = TOlapTableSink {
      load_id: f_1.expect("auto-generated code should have checked for presence of required fields"),
      txn_id: f_2.expect("auto-generated code should have checked for presence of required fields"),
      db_id: f_3.expect("auto-generated code should have checked for presence of required fields"),
      table_id: f_4.expect("auto-generated code should have checked for presence of required fields"),
      tuple_id: f_5.expect("auto-generated code should have checked for presence of required fields"),
      num_replicas: f_6.expect("auto-generated code should have checked for presence of required fields"),
      need_gen_rollup: f_7.expect("auto-generated code should have checked for presence of required fields"),
      db_name: f_8,
      table_name: f_9,
      schema: f_10.expect("auto-generated code should have checked for presence of required fields"),
      partition: f_11.expect("auto-generated code should have checked for presence of required fields"),
      location: f_12.expect("auto-generated code should have checked for presence of required fields"),
      nodes_info: f_13.expect("auto-generated code should have checked for presence of required fields"),
      load_channel_timeout_s: f_14,
      send_batch_parallelism: f_15,
      load_to_single_tablet: f_16,
      write_single_replica: f_17,
      slave_location: f_18,
      txn_timeout_s: f_19,
      write_file_cache: f_20,
      base_schema_version: f_21,
      group_commit_mode: f_22,
      max_filter_ratio: f_23,
      storage_vault_id: f_24,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TOlapTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("load_id", TType::Struct, 1))?;
    self.load_id.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("txn_id", TType::I64, 2))?;
    o_prot.write_i64(self.txn_id)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("db_id", TType::I64, 3))?;
    o_prot.write_i64(self.db_id)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("table_id", TType::I64, 4))?;
    o_prot.write_i64(self.table_id)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("tuple_id", TType::I32, 5))?;
    o_prot.write_i32(self.tuple_id)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("num_replicas", TType::I32, 6))?;
    o_prot.write_i32(self.num_replicas)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("need_gen_rollup", TType::Bool, 7))?;
    o_prot.write_bool(self.need_gen_rollup)?;
    o_prot.write_field_end()?;
    if let Some(ref fld_var) = self.db_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("db_name", TType::String, 8))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.table_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("table_name", TType::String, 9))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_begin(&TFieldIdentifier::new("schema", TType::Struct, 10))?;
    self.schema.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("partition", TType::Struct, 11))?;
    self.partition.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("location", TType::Struct, 12))?;
    self.location.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    o_prot.write_field_begin(&TFieldIdentifier::new("nodes_info", TType::Struct, 13))?;
    self.nodes_info.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    if let Some(fld_var) = self.load_channel_timeout_s {
      o_prot.write_field_begin(&TFieldIdentifier::new("load_channel_timeout_s", TType::I64, 14))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.send_batch_parallelism {
      o_prot.write_field_begin(&TFieldIdentifier::new("send_batch_parallelism", TType::I32, 15))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.load_to_single_tablet {
      o_prot.write_field_begin(&TFieldIdentifier::new("load_to_single_tablet", TType::Bool, 16))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.write_single_replica {
      o_prot.write_field_begin(&TFieldIdentifier::new("write_single_replica", TType::Bool, 17))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.slave_location {
      o_prot.write_field_begin(&TFieldIdentifier::new("slave_location", TType::Struct, 18))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.txn_timeout_s {
      o_prot.write_field_begin(&TFieldIdentifier::new("txn_timeout_s", TType::I64, 19))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.write_file_cache {
      o_prot.write_field_begin(&TFieldIdentifier::new("write_file_cache", TType::Bool, 20))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.base_schema_version {
      o_prot.write_field_begin(&TFieldIdentifier::new("base_schema_version", TType::I64, 21))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.group_commit_mode {
      o_prot.write_field_begin(&TFieldIdentifier::new("group_commit_mode", TType::I32, 22))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.max_filter_ratio {
      o_prot.write_field_begin(&TFieldIdentifier::new("max_filter_ratio", TType::Double, 23))?;
      o_prot.write_double(fld_var.into())?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.storage_vault_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("storage_vault_id", TType::String, 24))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THiveLocationParams
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveLocationParams {
  pub write_path: Option<String>,
  pub target_path: Option<String>,
  pub file_type: Option<types::TFileType>,
  pub original_write_path: Option<String>,
}

impl THiveLocationParams {
  pub fn new<F1, F2, F3, F4>(write_path: F1, target_path: F2, file_type: F3, original_write_path: F4) -> THiveLocationParams where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<types::TFileType>>, F4: Into<Option<String>> {
    THiveLocationParams {
      write_path: write_path.into(),
      target_path: target_path.into(),
      file_type: file_type.into(),
      original_write_path: original_write_path.into(),
    }
  }
}

impl TSerializable for THiveLocationParams {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveLocationParams> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<types::TFileType> = None;
    let mut f_4: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = types::TFileType::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THiveLocationParams {
      write_path: f_1,
      target_path: f_2,
      file_type: f_3,
      original_write_path: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THiveLocationParams");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.write_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("write_path", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.target_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("target_path", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_type", TType::I32, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.original_write_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("original_write_path", TType::String, 4))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TSortedColumn
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TSortedColumn {
  pub sort_column_name: Option<String>,
  pub order: Option<i32>,
}

impl TSortedColumn {
  pub fn new<F1, F2>(sort_column_name: F1, order: F2) -> TSortedColumn where F1: Into<Option<String>>, F2: Into<Option<i32>> {
    TSortedColumn {
      sort_column_name: sort_column_name.into(),
      order: order.into(),
    }
  }
}

impl TSerializable for TSortedColumn {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TSortedColumn> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<i32> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_i32()?;
          f_2 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TSortedColumn {
      sort_column_name: f_1,
      order: f_2,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TSortedColumn");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.sort_column_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("sort_column_name", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.order {
      o_prot.write_field_begin(&TFieldIdentifier::new("order", TType::I32, 2))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TBucketingMode
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TBucketingMode {
  pub bucket_version: Option<i32>,
}

impl TBucketingMode {
  pub fn new<F1>(bucket_version: F1) -> TBucketingMode where F1: Into<Option<i32>> {
    TBucketingMode {
      bucket_version: bucket_version.into(),
    }
  }
}

impl TSerializable for TBucketingMode {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TBucketingMode> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<i32> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_i32()?;
          f_1 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TBucketingMode {
      bucket_version: f_1,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TBucketingMode");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(fld_var) = self.bucket_version {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucket_version", TType::I32, 1))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THiveBucket
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveBucket {
  pub bucketed_by: Option<Vec<String>>,
  pub bucket_mode: Option<TBucketingMode>,
  pub bucket_count: Option<i32>,
  pub sorted_by: Option<Vec<TSortedColumn>>,
}

impl THiveBucket {
  pub fn new<F1, F2, F3, F4>(bucketed_by: F1, bucket_mode: F2, bucket_count: F3, sorted_by: F4) -> THiveBucket where F1: Into<Option<Vec<String>>>, F2: Into<Option<TBucketingMode>>, F3: Into<Option<i32>>, F4: Into<Option<Vec<TSortedColumn>>> {
    THiveBucket {
      bucketed_by: bucketed_by.into(),
      bucket_mode: bucket_mode.into(),
      bucket_count: bucket_count.into(),
      sorted_by: sorted_by.into(),
    }
  }
}

impl TSerializable for THiveBucket {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveBucket> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<Vec<String>> = None;
    let mut f_2: Option<TBucketingMode> = None;
    let mut f_3: Option<i32> = None;
    let mut f_4: Option<Vec<TSortedColumn>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_19 = i_prot.read_string()?;
            val.push(list_elem_19);
          }
          i_prot.read_list_end()?;
          f_1 = Some(val);
        },
        2 => {
          let val = TBucketingMode::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_i32()?;
          f_3 = Some(val);
        },
        4 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<TSortedColumn> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_20 = TSortedColumn::read_from_in_protocol(i_prot)?;
            val.push(list_elem_20);
          }
          i_prot.read_list_end()?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THiveBucket {
      bucketed_by: f_1,
      bucket_mode: f_2,
      bucket_count: f_3,
      sorted_by: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THiveBucket");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.bucketed_by {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucketed_by", TType::List, 1))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.bucket_mode {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucket_mode", TType::Struct, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.bucket_count {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucket_count", TType::I32, 3))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.sorted_by {
      o_prot.write_field_begin(&TFieldIdentifier::new("sorted_by", TType::List, 4))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THiveColumn
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveColumn {
  pub name: Option<String>,
  pub column_type: Option<THiveColumnType>,
}

impl THiveColumn {
  pub fn new<F1, F2>(name: F1, column_type: F2) -> THiveColumn where F1: Into<Option<String>>, F2: Into<Option<THiveColumnType>> {
    THiveColumn {
      name: name.into(),
      column_type: column_type.into(),
    }
  }
}

impl TSerializable for THiveColumn {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveColumn> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<THiveColumnType> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = THiveColumnType::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THiveColumn {
      name: f_1,
      column_type: f_2,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THiveColumn");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.name {
      o_prot.write_field_begin(&TFieldIdentifier::new("name", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.column_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("column_type", TType::I32, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THivePartition
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THivePartition {
  pub values: Option<Vec<String>>,
  pub location: Option<THiveLocationParams>,
  pub file_format: Option<plan_nodes::TFileFormatType>,
}

impl THivePartition {
  pub fn new<F1, F2, F3>(values: F1, location: F2, file_format: F3) -> THivePartition where F1: Into<Option<Vec<String>>>, F2: Into<Option<THiveLocationParams>>, F3: Into<Option<plan_nodes::TFileFormatType>> {
    THivePartition {
      values: values.into(),
      location: location.into(),
      file_format: file_format.into(),
    }
  }
}

impl TSerializable for THivePartition {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THivePartition> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<Vec<String>> = None;
    let mut f_2: Option<THiveLocationParams> = None;
    let mut f_3: Option<plan_nodes::TFileFormatType> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_21 = i_prot.read_string()?;
            val.push(list_elem_21);
          }
          i_prot.read_list_end()?;
          f_1 = Some(val);
        },
        2 => {
          let val = THiveLocationParams::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = plan_nodes::TFileFormatType::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THivePartition {
      values: f_1,
      location: f_2,
      file_format: f_3,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THivePartition");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.values {
      o_prot.write_field_begin(&TFieldIdentifier::new("values", TType::List, 1))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.location {
      o_prot.write_field_begin(&TFieldIdentifier::new("location", TType::Struct, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_format {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_format", TType::I32, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THiveSerDeProperties
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveSerDeProperties {
  pub field_delim: Option<String>,
  pub line_delim: Option<String>,
  pub collection_delim: Option<String>,
  pub mapkv_delim: Option<String>,
  pub escape_char: Option<String>,
  pub null_format: Option<String>,
}

impl THiveSerDeProperties {
  pub fn new<F1, F2, F3, F4, F5, F6>(field_delim: F1, line_delim: F2, collection_delim: F3, mapkv_delim: F4, escape_char: F5, null_format: F6) -> THiveSerDeProperties where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<String>>, F4: Into<Option<String>>, F5: Into<Option<String>>, F6: Into<Option<String>> {
    THiveSerDeProperties {
      field_delim: field_delim.into(),
      line_delim: line_delim.into(),
      collection_delim: collection_delim.into(),
      mapkv_delim: mapkv_delim.into(),
      escape_char: escape_char.into(),
      null_format: null_format.into(),
    }
  }
}

impl TSerializable for THiveSerDeProperties {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveSerDeProperties> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<String> = None;
    let mut f_5: Option<String> = None;
    let mut f_6: Option<String> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = i_prot.read_string()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_string()?;
          f_5 = Some(val);
        },
        6 => {
          let val = i_prot.read_string()?;
          f_6 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THiveSerDeProperties {
      field_delim: f_1,
      line_delim: f_2,
      collection_delim: f_3,
      mapkv_delim: f_4,
      escape_char: f_5,
      null_format: f_6,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THiveSerDeProperties");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.field_delim {
      o_prot.write_field_begin(&TFieldIdentifier::new("field_delim", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.line_delim {
      o_prot.write_field_begin(&TFieldIdentifier::new("line_delim", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.collection_delim {
      o_prot.write_field_begin(&TFieldIdentifier::new("collection_delim", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.mapkv_delim {
      o_prot.write_field_begin(&TFieldIdentifier::new("mapkv_delim", TType::String, 4))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.escape_char {
      o_prot.write_field_begin(&TFieldIdentifier::new("escape_char", TType::String, 5))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.null_format {
      o_prot.write_field_begin(&TFieldIdentifier::new("null_format", TType::String, 6))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THiveTableSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THiveTableSink {
  pub db_name: Option<String>,
  pub table_name: Option<String>,
  pub columns: Option<Vec<THiveColumn>>,
  pub partitions: Option<Vec<THivePartition>>,
  pub bucket_info: Option<THiveBucket>,
  pub file_format: Option<plan_nodes::TFileFormatType>,
  pub compression_type: Option<plan_nodes::TFileCompressType>,
  pub location: Option<THiveLocationParams>,
  pub hadoop_config: Option<BTreeMap<String, String>>,
  pub overwrite: Option<bool>,
  pub serde_properties: Option<THiveSerDeProperties>,
  pub broker_addresses: Option<Vec<types::TNetworkAddress>>,
}

impl THiveTableSink {
  pub fn new<F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12>(db_name: F1, table_name: F2, columns: F3, partitions: F4, bucket_info: F5, file_format: F6, compression_type: F7, location: F8, hadoop_config: F9, overwrite: F10, serde_properties: F11, broker_addresses: F12) -> THiveTableSink where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<Vec<THiveColumn>>>, F4: Into<Option<Vec<THivePartition>>>, F5: Into<Option<THiveBucket>>, F6: Into<Option<plan_nodes::TFileFormatType>>, F7: Into<Option<plan_nodes::TFileCompressType>>, F8: Into<Option<THiveLocationParams>>, F9: Into<Option<BTreeMap<String, String>>>, F10: Into<Option<bool>>, F11: Into<Option<THiveSerDeProperties>>, F12: Into<Option<Vec<types::TNetworkAddress>>> {
    THiveTableSink {
      db_name: db_name.into(),
      table_name: table_name.into(),
      columns: columns.into(),
      partitions: partitions.into(),
      bucket_info: bucket_info.into(),
      file_format: file_format.into(),
      compression_type: compression_type.into(),
      location: location.into(),
      hadoop_config: hadoop_config.into(),
      overwrite: overwrite.into(),
      serde_properties: serde_properties.into(),
      broker_addresses: broker_addresses.into(),
    }
  }
}

impl TSerializable for THiveTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THiveTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<Vec<THiveColumn>> = None;
    let mut f_4: Option<Vec<THivePartition>> = None;
    let mut f_5: Option<THiveBucket> = None;
    let mut f_6: Option<plan_nodes::TFileFormatType> = None;
    let mut f_7: Option<plan_nodes::TFileCompressType> = None;
    let mut f_8: Option<THiveLocationParams> = None;
    let mut f_9: Option<BTreeMap<String, String>> = None;
    let mut f_10: Option<bool> = None;
    let mut f_11: Option<THiveSerDeProperties> = None;
    let mut f_12: Option<Vec<types::TNetworkAddress>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<THiveColumn> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_22 = THiveColumn::read_from_in_protocol(i_prot)?;
            val.push(list_elem_22);
          }
          i_prot.read_list_end()?;
          f_3 = Some(val);
        },
        4 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<THivePartition> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_23 = THivePartition::read_from_in_protocol(i_prot)?;
            val.push(list_elem_23);
          }
          i_prot.read_list_end()?;
          f_4 = Some(val);
        },
        5 => {
          let val = THiveBucket::read_from_in_protocol(i_prot)?;
          f_5 = Some(val);
        },
        6 => {
          let val = plan_nodes::TFileFormatType::read_from_in_protocol(i_prot)?;
          f_6 = Some(val);
        },
        7 => {
          let val = plan_nodes::TFileCompressType::read_from_in_protocol(i_prot)?;
          f_7 = Some(val);
        },
        8 => {
          let val = THiveLocationParams::read_from_in_protocol(i_prot)?;
          f_8 = Some(val);
        },
        9 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<String, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_24 = i_prot.read_string()?;
            let map_val_25 = i_prot.read_string()?;
            val.insert(map_key_24, map_val_25);
          }
          i_prot.read_map_end()?;
          f_9 = Some(val);
        },
        10 => {
          let val = i_prot.read_bool()?;
          f_10 = Some(val);
        },
        11 => {
          let val = THiveSerDeProperties::read_from_in_protocol(i_prot)?;
          f_11 = Some(val);
        },
        12 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<types::TNetworkAddress> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_26 = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
            val.push(list_elem_26);
          }
          i_prot.read_list_end()?;
          f_12 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THiveTableSink {
      db_name: f_1,
      table_name: f_2,
      columns: f_3,
      partitions: f_4,
      bucket_info: f_5,
      file_format: f_6,
      compression_type: f_7,
      location: f_8,
      hadoop_config: f_9,
      overwrite: f_10,
      serde_properties: f_11,
      broker_addresses: f_12,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THiveTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.db_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("db_name", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.table_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("table_name", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.columns {
      o_prot.write_field_begin(&TFieldIdentifier::new("columns", TType::List, 3))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.partitions {
      o_prot.write_field_begin(&TFieldIdentifier::new("partitions", TType::List, 4))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.bucket_info {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucket_info", TType::Struct, 5))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_format {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_format", TType::I32, 6))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.compression_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("compression_type", TType::I32, 7))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.location {
      o_prot.write_field_begin(&TFieldIdentifier::new("location", TType::Struct, 8))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.hadoop_config {
      o_prot.write_field_begin(&TFieldIdentifier::new("hadoop_config", TType::Map, 9))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::String, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_string(k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.overwrite {
      o_prot.write_field_begin(&TFieldIdentifier::new("overwrite", TType::Bool, 10))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.serde_properties {
      o_prot.write_field_begin(&TFieldIdentifier::new("serde_properties", TType::Struct, 11))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.broker_addresses {
      o_prot.write_field_begin(&TFieldIdentifier::new("broker_addresses", TType::List, 12))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TS3MPUPendingUpload
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TS3MPUPendingUpload {
  pub bucket: Option<String>,
  pub key: Option<String>,
  pub upload_id: Option<String>,
  pub etags: Option<BTreeMap<i32, String>>,
}

impl TS3MPUPendingUpload {
  pub fn new<F1, F2, F3, F4>(bucket: F1, key: F2, upload_id: F3, etags: F4) -> TS3MPUPendingUpload where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<String>>, F4: Into<Option<BTreeMap<i32, String>>> {
    TS3MPUPendingUpload {
      bucket: bucket.into(),
      key: key.into(),
      upload_id: upload_id.into(),
      etags: etags.into(),
    }
  }
}

impl TSerializable for TS3MPUPendingUpload {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TS3MPUPendingUpload> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<BTreeMap<i32, String>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<i32, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_27 = i_prot.read_i32()?;
            let map_val_28 = i_prot.read_string()?;
            val.insert(map_key_27, map_val_28);
          }
          i_prot.read_map_end()?;
          f_4 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TS3MPUPendingUpload {
      bucket: f_1,
      key: f_2,
      upload_id: f_3,
      etags: f_4,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TS3MPUPendingUpload");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.bucket {
      o_prot.write_field_begin(&TFieldIdentifier::new("bucket", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.key {
      o_prot.write_field_begin(&TFieldIdentifier::new("key", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.upload_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("upload_id", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.etags {
      o_prot.write_field_begin(&TFieldIdentifier::new("etags", TType::Map, 4))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::I32, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_i32(*k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// THivePartitionUpdate
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct THivePartitionUpdate {
  pub name: Option<String>,
  pub update_mode: Option<TUpdateMode>,
  pub location: Option<THiveLocationParams>,
  pub file_names: Option<Vec<String>>,
  pub row_count: Option<i64>,
  pub file_size: Option<i64>,
  pub s3_mpu_pending_uploads: Option<Vec<TS3MPUPendingUpload>>,
}

impl THivePartitionUpdate {
  pub fn new<F1, F2, F3, F4, F5, F6, F7>(name: F1, update_mode: F2, location: F3, file_names: F4, row_count: F5, file_size: F6, s3_mpu_pending_uploads: F7) -> THivePartitionUpdate where F1: Into<Option<String>>, F2: Into<Option<TUpdateMode>>, F3: Into<Option<THiveLocationParams>>, F4: Into<Option<Vec<String>>>, F5: Into<Option<i64>>, F6: Into<Option<i64>>, F7: Into<Option<Vec<TS3MPUPendingUpload>>> {
    THivePartitionUpdate {
      name: name.into(),
      update_mode: update_mode.into(),
      location: location.into(),
      file_names: file_names.into(),
      row_count: row_count.into(),
      file_size: file_size.into(),
      s3_mpu_pending_uploads: s3_mpu_pending_uploads.into(),
    }
  }
}

impl TSerializable for THivePartitionUpdate {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<THivePartitionUpdate> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<TUpdateMode> = None;
    let mut f_3: Option<THiveLocationParams> = None;
    let mut f_4: Option<Vec<String>> = None;
    let mut f_5: Option<i64> = None;
    let mut f_6: Option<i64> = None;
    let mut f_7: Option<Vec<TS3MPUPendingUpload>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = TUpdateMode::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = THiveLocationParams::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        4 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_29 = i_prot.read_string()?;
            val.push(list_elem_29);
          }
          i_prot.read_list_end()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_i64()?;
          f_5 = Some(val);
        },
        6 => {
          let val = i_prot.read_i64()?;
          f_6 = Some(val);
        },
        7 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<TS3MPUPendingUpload> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_30 = TS3MPUPendingUpload::read_from_in_protocol(i_prot)?;
            val.push(list_elem_30);
          }
          i_prot.read_list_end()?;
          f_7 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = THivePartitionUpdate {
      name: f_1,
      update_mode: f_2,
      location: f_3,
      file_names: f_4,
      row_count: f_5,
      file_size: f_6,
      s3_mpu_pending_uploads: f_7,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("THivePartitionUpdate");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.name {
      o_prot.write_field_begin(&TFieldIdentifier::new("name", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.update_mode {
      o_prot.write_field_begin(&TFieldIdentifier::new("update_mode", TType::I32, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.location {
      o_prot.write_field_begin(&TFieldIdentifier::new("location", TType::Struct, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_names {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_names", TType::List, 4))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.row_count {
      o_prot.write_field_begin(&TFieldIdentifier::new("row_count", TType::I64, 5))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.file_size {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_size", TType::I64, 6))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.s3_mpu_pending_uploads {
      o_prot.write_field_begin(&TFieldIdentifier::new("s3_mpu_pending_uploads", TType::List, 7))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TIcebergCommitData
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TIcebergCommitData {
  pub file_path: Option<String>,
  pub row_count: Option<i64>,
  pub file_size: Option<i64>,
  pub file_content: Option<TFileContent>,
  pub partition_values: Option<Vec<String>>,
  pub referenced_data_files: Option<Vec<String>>,
}

impl TIcebergCommitData {
  pub fn new<F1, F2, F3, F4, F5, F6>(file_path: F1, row_count: F2, file_size: F3, file_content: F4, partition_values: F5, referenced_data_files: F6) -> TIcebergCommitData where F1: Into<Option<String>>, F2: Into<Option<i64>>, F3: Into<Option<i64>>, F4: Into<Option<TFileContent>>, F5: Into<Option<Vec<String>>>, F6: Into<Option<Vec<String>>> {
    TIcebergCommitData {
      file_path: file_path.into(),
      row_count: row_count.into(),
      file_size: file_size.into(),
      file_content: file_content.into(),
      partition_values: partition_values.into(),
      referenced_data_files: referenced_data_files.into(),
    }
  }
}

impl TSerializable for TIcebergCommitData {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TIcebergCommitData> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<i64> = None;
    let mut f_3: Option<i64> = None;
    let mut f_4: Option<TFileContent> = None;
    let mut f_5: Option<Vec<String>> = None;
    let mut f_6: Option<Vec<String>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_i64()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_i64()?;
          f_3 = Some(val);
        },
        4 => {
          let val = TFileContent::read_from_in_protocol(i_prot)?;
          f_4 = Some(val);
        },
        5 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_31 = i_prot.read_string()?;
            val.push(list_elem_31);
          }
          i_prot.read_list_end()?;
          f_5 = Some(val);
        },
        6 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_32 = i_prot.read_string()?;
            val.push(list_elem_32);
          }
          i_prot.read_list_end()?;
          f_6 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TIcebergCommitData {
      file_path: f_1,
      row_count: f_2,
      file_size: f_3,
      file_content: f_4,
      partition_values: f_5,
      referenced_data_files: f_6,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TIcebergCommitData");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.file_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_path", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.row_count {
      o_prot.write_field_begin(&TFieldIdentifier::new("row_count", TType::I64, 2))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.file_size {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_size", TType::I64, 3))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_content {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_content", TType::I32, 4))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.partition_values {
      o_prot.write_field_begin(&TFieldIdentifier::new("partition_values", TType::List, 5))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.referenced_data_files {
      o_prot.write_field_begin(&TFieldIdentifier::new("referenced_data_files", TType::List, 6))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TSortField
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TSortField {
  pub source_column_id: Option<i32>,
  pub ascending: Option<bool>,
  pub null_first: Option<bool>,
}

impl TSortField {
  pub fn new<F1, F2, F3>(source_column_id: F1, ascending: F2, null_first: F3) -> TSortField where F1: Into<Option<i32>>, F2: Into<Option<bool>>, F3: Into<Option<bool>> {
    TSortField {
      source_column_id: source_column_id.into(),
      ascending: ascending.into(),
      null_first: null_first.into(),
    }
  }
}

impl TSerializable for TSortField {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TSortField> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<i32> = None;
    let mut f_2: Option<bool> = None;
    let mut f_3: Option<bool> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_i32()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_bool()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_bool()?;
          f_3 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TSortField {
      source_column_id: f_1,
      ascending: f_2,
      null_first: f_3,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TSortField");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(fld_var) = self.source_column_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("source_column_id", TType::I32, 1))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.ascending {
      o_prot.write_field_begin(&TFieldIdentifier::new("ascending", TType::Bool, 2))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.null_first {
      o_prot.write_field_begin(&TFieldIdentifier::new("null_first", TType::Bool, 3))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TIcebergTableSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TIcebergTableSink {
  pub db_name: Option<String>,
  pub tb_name: Option<String>,
  pub schema_json: Option<String>,
  pub partition_specs_json: Option<BTreeMap<i32, String>>,
  pub partition_spec_id: Option<i32>,
  pub sort_fields: Option<Vec<TSortField>>,
  pub file_format: Option<plan_nodes::TFileFormatType>,
  pub output_path: Option<String>,
  pub hadoop_config: Option<BTreeMap<String, String>>,
  pub overwrite: Option<bool>,
  pub file_type: Option<types::TFileType>,
  pub original_output_path: Option<String>,
  pub compression_type: Option<plan_nodes::TFileCompressType>,
  pub broker_addresses: Option<Vec<types::TNetworkAddress>>,
}

impl TIcebergTableSink {
  pub fn new<F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14>(db_name: F1, tb_name: F2, schema_json: F3, partition_specs_json: F4, partition_spec_id: F5, sort_fields: F6, file_format: F7, output_path: F8, hadoop_config: F9, overwrite: F10, file_type: F11, original_output_path: F12, compression_type: F13, broker_addresses: F14) -> TIcebergTableSink where F1: Into<Option<String>>, F2: Into<Option<String>>, F3: Into<Option<String>>, F4: Into<Option<BTreeMap<i32, String>>>, F5: Into<Option<i32>>, F6: Into<Option<Vec<TSortField>>>, F7: Into<Option<plan_nodes::TFileFormatType>>, F8: Into<Option<String>>, F9: Into<Option<BTreeMap<String, String>>>, F10: Into<Option<bool>>, F11: Into<Option<types::TFileType>>, F12: Into<Option<String>>, F13: Into<Option<plan_nodes::TFileCompressType>>, F14: Into<Option<Vec<types::TNetworkAddress>>> {
    TIcebergTableSink {
      db_name: db_name.into(),
      tb_name: tb_name.into(),
      schema_json: schema_json.into(),
      partition_specs_json: partition_specs_json.into(),
      partition_spec_id: partition_spec_id.into(),
      sort_fields: sort_fields.into(),
      file_format: file_format.into(),
      output_path: output_path.into(),
      hadoop_config: hadoop_config.into(),
      overwrite: overwrite.into(),
      file_type: file_type.into(),
      original_output_path: original_output_path.into(),
      compression_type: compression_type.into(),
      broker_addresses: broker_addresses.into(),
    }
  }
}

impl TSerializable for TIcebergTableSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TIcebergTableSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<String> = None;
    let mut f_2: Option<String> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<BTreeMap<i32, String>> = None;
    let mut f_5: Option<i32> = None;
    let mut f_6: Option<Vec<TSortField>> = None;
    let mut f_7: Option<plan_nodes::TFileFormatType> = None;
    let mut f_8: Option<String> = None;
    let mut f_9: Option<BTreeMap<String, String>> = None;
    let mut f_10: Option<bool> = None;
    let mut f_11: Option<types::TFileType> = None;
    let mut f_12: Option<String> = None;
    let mut f_13: Option<plan_nodes::TFileCompressType> = None;
    let mut f_14: Option<Vec<types::TNetworkAddress>> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_string()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_string()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<i32, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_33 = i_prot.read_i32()?;
            let map_val_34 = i_prot.read_string()?;
            val.insert(map_key_33, map_val_34);
          }
          i_prot.read_map_end()?;
          f_4 = Some(val);
        },
        5 => {
          let val = i_prot.read_i32()?;
          f_5 = Some(val);
        },
        6 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<TSortField> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_35 = TSortField::read_from_in_protocol(i_prot)?;
            val.push(list_elem_35);
          }
          i_prot.read_list_end()?;
          f_6 = Some(val);
        },
        7 => {
          let val = plan_nodes::TFileFormatType::read_from_in_protocol(i_prot)?;
          f_7 = Some(val);
        },
        8 => {
          let val = i_prot.read_string()?;
          f_8 = Some(val);
        },
        9 => {
          let map_ident = i_prot.read_map_begin()?;
          let mut val: BTreeMap<String, String> = BTreeMap::new();
          for _ in 0..map_ident.size {
            let map_key_36 = i_prot.read_string()?;
            let map_val_37 = i_prot.read_string()?;
            val.insert(map_key_36, map_val_37);
          }
          i_prot.read_map_end()?;
          f_9 = Some(val);
        },
        10 => {
          let val = i_prot.read_bool()?;
          f_10 = Some(val);
        },
        11 => {
          let val = types::TFileType::read_from_in_protocol(i_prot)?;
          f_11 = Some(val);
        },
        12 => {
          let val = i_prot.read_string()?;
          f_12 = Some(val);
        },
        13 => {
          let val = plan_nodes::TFileCompressType::read_from_in_protocol(i_prot)?;
          f_13 = Some(val);
        },
        14 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<types::TNetworkAddress> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_38 = types::TNetworkAddress::read_from_in_protocol(i_prot)?;
            val.push(list_elem_38);
          }
          i_prot.read_list_end()?;
          f_14 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TIcebergTableSink {
      db_name: f_1,
      tb_name: f_2,
      schema_json: f_3,
      partition_specs_json: f_4,
      partition_spec_id: f_5,
      sort_fields: f_6,
      file_format: f_7,
      output_path: f_8,
      hadoop_config: f_9,
      overwrite: f_10,
      file_type: f_11,
      original_output_path: f_12,
      compression_type: f_13,
      broker_addresses: f_14,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TIcebergTableSink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(ref fld_var) = self.db_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("db_name", TType::String, 1))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.tb_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("tb_name", TType::String, 2))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.schema_json {
      o_prot.write_field_begin(&TFieldIdentifier::new("schema_json", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.partition_specs_json {
      o_prot.write_field_begin(&TFieldIdentifier::new("partition_specs_json", TType::Map, 4))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::I32, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_i32(*k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.partition_spec_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("partition_spec_id", TType::I32, 5))?;
      o_prot.write_i32(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.sort_fields {
      o_prot.write_field_begin(&TFieldIdentifier::new("sort_fields", TType::List, 6))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_format {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_format", TType::I32, 7))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.output_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("output_path", TType::String, 8))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.hadoop_config {
      o_prot.write_field_begin(&TFieldIdentifier::new("hadoop_config", TType::Map, 9))?;
      o_prot.write_map_begin(&TMapIdentifier::new(TType::String, TType::String, fld_var.len() as i32))?;
      for (k, v) in fld_var {
        o_prot.write_string(k)?;
        o_prot.write_string(v)?;
      }
      o_prot.write_map_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.overwrite {
      o_prot.write_field_begin(&TFieldIdentifier::new("overwrite", TType::Bool, 10))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.file_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("file_type", TType::I32, 11))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.original_output_path {
      o_prot.write_field_begin(&TFieldIdentifier::new("original_output_path", TType::String, 12))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.compression_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("compression_type", TType::I32, 13))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.broker_addresses {
      o_prot.write_field_begin(&TFieldIdentifier::new("broker_addresses", TType::List, 14))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::Struct, fld_var.len() as i32))?;
      for e in fld_var {
        e.write_to_out_protocol(o_prot)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TDictionarySink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TDictionarySink {
  pub dictionary_id: Option<i64>,
  pub version_id: Option<i64>,
  pub dictionary_name: Option<String>,
  pub layout_type: Option<TDictLayoutType>,
  pub key_output_expr_slots: Option<Vec<i64>>,
  pub value_output_expr_slots: Option<Vec<i64>>,
  pub value_names: Option<Vec<String>>,
  pub skip_null_key: Option<bool>,
  pub memory_limit: Option<i64>,
}

impl TDictionarySink {
  pub fn new<F1, F2, F3, F4, F5, F6, F7, F8, F9>(dictionary_id: F1, version_id: F2, dictionary_name: F3, layout_type: F4, key_output_expr_slots: F5, value_output_expr_slots: F6, value_names: F7, skip_null_key: F8, memory_limit: F9) -> TDictionarySink where F1: Into<Option<i64>>, F2: Into<Option<i64>>, F3: Into<Option<String>>, F4: Into<Option<TDictLayoutType>>, F5: Into<Option<Vec<i64>>>, F6: Into<Option<Vec<i64>>>, F7: Into<Option<Vec<String>>>, F8: Into<Option<bool>>, F9: Into<Option<i64>> {
    TDictionarySink {
      dictionary_id: dictionary_id.into(),
      version_id: version_id.into(),
      dictionary_name: dictionary_name.into(),
      layout_type: layout_type.into(),
      key_output_expr_slots: key_output_expr_slots.into(),
      value_output_expr_slots: value_output_expr_slots.into(),
      value_names: value_names.into(),
      skip_null_key: skip_null_key.into(),
      memory_limit: memory_limit.into(),
    }
  }
}

impl TSerializable for TDictionarySink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TDictionarySink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<i64> = None;
    let mut f_2: Option<i64> = None;
    let mut f_3: Option<String> = None;
    let mut f_4: Option<TDictLayoutType> = None;
    let mut f_5: Option<Vec<i64>> = None;
    let mut f_6: Option<Vec<i64>> = None;
    let mut f_7: Option<Vec<String>> = None;
    let mut f_8: Option<bool> = None;
    let mut f_9: Option<i64> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = i_prot.read_i64()?;
          f_1 = Some(val);
        },
        2 => {
          let val = i_prot.read_i64()?;
          f_2 = Some(val);
        },
        3 => {
          let val = i_prot.read_string()?;
          f_3 = Some(val);
        },
        4 => {
          let val = TDictLayoutType::read_from_in_protocol(i_prot)?;
          f_4 = Some(val);
        },
        5 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<i64> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_39 = i_prot.read_i64()?;
            val.push(list_elem_39);
          }
          i_prot.read_list_end()?;
          f_5 = Some(val);
        },
        6 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<i64> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_40 = i_prot.read_i64()?;
            val.push(list_elem_40);
          }
          i_prot.read_list_end()?;
          f_6 = Some(val);
        },
        7 => {
          let list_ident = i_prot.read_list_begin()?;
          let mut val: Vec<String> = Vec::with_capacity(list_ident.size as usize);
          for _ in 0..list_ident.size {
            let list_elem_41 = i_prot.read_string()?;
            val.push(list_elem_41);
          }
          i_prot.read_list_end()?;
          f_7 = Some(val);
        },
        8 => {
          let val = i_prot.read_bool()?;
          f_8 = Some(val);
        },
        9 => {
          let val = i_prot.read_i64()?;
          f_9 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TDictionarySink {
      dictionary_id: f_1,
      version_id: f_2,
      dictionary_name: f_3,
      layout_type: f_4,
      key_output_expr_slots: f_5,
      value_output_expr_slots: f_6,
      value_names: f_7,
      skip_null_key: f_8,
      memory_limit: f_9,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TDictionarySink");
    o_prot.write_struct_begin(&struct_ident)?;
    if let Some(fld_var) = self.dictionary_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("dictionary_id", TType::I64, 1))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.version_id {
      o_prot.write_field_begin(&TFieldIdentifier::new("version_id", TType::I64, 2))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.dictionary_name {
      o_prot.write_field_begin(&TFieldIdentifier::new("dictionary_name", TType::String, 3))?;
      o_prot.write_string(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.layout_type {
      o_prot.write_field_begin(&TFieldIdentifier::new("layout_type", TType::I32, 4))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.key_output_expr_slots {
      o_prot.write_field_begin(&TFieldIdentifier::new("key_output_expr_slots", TType::List, 5))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::I64, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_i64(*e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.value_output_expr_slots {
      o_prot.write_field_begin(&TFieldIdentifier::new("value_output_expr_slots", TType::List, 6))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::I64, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_i64(*e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.value_names {
      o_prot.write_field_begin(&TFieldIdentifier::new("value_names", TType::List, 7))?;
      o_prot.write_list_begin(&TListIdentifier::new(TType::String, fld_var.len() as i32))?;
      for e in fld_var {
        o_prot.write_string(e)?;
      }
      o_prot.write_list_end()?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.skip_null_key {
      o_prot.write_field_begin(&TFieldIdentifier::new("skip_null_key", TType::Bool, 8))?;
      o_prot.write_bool(fld_var)?;
      o_prot.write_field_end()?
    }
    if let Some(fld_var) = self.memory_limit {
      o_prot.write_field_begin(&TFieldIdentifier::new("memory_limit", TType::I64, 9))?;
      o_prot.write_i64(fld_var)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TBlackholeSink
//

#[derive(Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TBlackholeSink {
}

impl TBlackholeSink {
  pub fn new() -> TBlackholeSink {
    TBlackholeSink {}
  }
}

impl TSerializable for TBlackholeSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TBlackholeSink> {
    i_prot.read_struct_begin()?;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      i_prot.skip(field_ident.field_type)?;
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    let ret = TBlackholeSink {};
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TBlackholeSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

//
// TDataSink
//

#[derive(Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct TDataSink {
  pub type_: TDataSinkType,
  pub stream_sink: Option<TDataStreamSink>,
  pub result_sink: Option<TResultSink>,
  pub mysql_table_sink: Option<TMysqlTableSink>,
  pub export_sink: Option<TExportSink>,
  pub olap_table_sink: Option<TOlapTableSink>,
  pub memory_scratch_sink: Option<TMemoryScratchSink>,
  pub odbc_table_sink: Option<TOdbcTableSink>,
  pub result_file_sink: Option<TResultFileSink>,
  pub jdbc_table_sink: Option<TJdbcTableSink>,
  pub multi_cast_stream_sink: Option<TMultiCastDataStreamSink>,
  pub hive_table_sink: Option<THiveTableSink>,
  pub iceberg_table_sink: Option<TIcebergTableSink>,
  pub dictionary_sink: Option<TDictionarySink>,
  pub blackhole_sink: Option<TBlackholeSink>,
}

impl TDataSink {
  pub fn new<F2, F3, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16>(type_: TDataSinkType, stream_sink: F2, result_sink: F3, mysql_table_sink: F5, export_sink: F6, olap_table_sink: F7, memory_scratch_sink: F8, odbc_table_sink: F9, result_file_sink: F10, jdbc_table_sink: F11, multi_cast_stream_sink: F12, hive_table_sink: F13, iceberg_table_sink: F14, dictionary_sink: F15, blackhole_sink: F16) -> TDataSink where F2: Into<Option<TDataStreamSink>>, F3: Into<Option<TResultSink>>, F5: Into<Option<TMysqlTableSink>>, F6: Into<Option<TExportSink>>, F7: Into<Option<TOlapTableSink>>, F8: Into<Option<TMemoryScratchSink>>, F9: Into<Option<TOdbcTableSink>>, F10: Into<Option<TResultFileSink>>, F11: Into<Option<TJdbcTableSink>>, F12: Into<Option<TMultiCastDataStreamSink>>, F13: Into<Option<THiveTableSink>>, F14: Into<Option<TIcebergTableSink>>, F15: Into<Option<TDictionarySink>>, F16: Into<Option<TBlackholeSink>> {
    TDataSink {
      type_,
      stream_sink: stream_sink.into(),
      result_sink: result_sink.into(),
      mysql_table_sink: mysql_table_sink.into(),
      export_sink: export_sink.into(),
      olap_table_sink: olap_table_sink.into(),
      memory_scratch_sink: memory_scratch_sink.into(),
      odbc_table_sink: odbc_table_sink.into(),
      result_file_sink: result_file_sink.into(),
      jdbc_table_sink: jdbc_table_sink.into(),
      multi_cast_stream_sink: multi_cast_stream_sink.into(),
      hive_table_sink: hive_table_sink.into(),
      iceberg_table_sink: iceberg_table_sink.into(),
      dictionary_sink: dictionary_sink.into(),
      blackhole_sink: blackhole_sink.into(),
    }
  }
}

impl TSerializable for TDataSink {
  fn read_from_in_protocol(i_prot: &mut dyn TInputProtocol) -> thrift::Result<TDataSink> {
    i_prot.read_struct_begin()?;
    let mut f_1: Option<TDataSinkType> = None;
    let mut f_2: Option<TDataStreamSink> = None;
    let mut f_3: Option<TResultSink> = None;
    let mut f_5: Option<TMysqlTableSink> = None;
    let mut f_6: Option<TExportSink> = None;
    let mut f_7: Option<TOlapTableSink> = None;
    let mut f_8: Option<TMemoryScratchSink> = None;
    let mut f_9: Option<TOdbcTableSink> = None;
    let mut f_10: Option<TResultFileSink> = None;
    let mut f_11: Option<TJdbcTableSink> = None;
    let mut f_12: Option<TMultiCastDataStreamSink> = None;
    let mut f_13: Option<THiveTableSink> = None;
    let mut f_14: Option<TIcebergTableSink> = None;
    let mut f_15: Option<TDictionarySink> = None;
    let mut f_16: Option<TBlackholeSink> = None;
    loop {
      let field_ident = i_prot.read_field_begin()?;
      if field_ident.field_type == TType::Stop {
        break;
      }
      let field_id = field_id(&field_ident)?;
      match field_id {
        1 => {
          let val = TDataSinkType::read_from_in_protocol(i_prot)?;
          f_1 = Some(val);
        },
        2 => {
          let val = TDataStreamSink::read_from_in_protocol(i_prot)?;
          f_2 = Some(val);
        },
        3 => {
          let val = TResultSink::read_from_in_protocol(i_prot)?;
          f_3 = Some(val);
        },
        5 => {
          let val = TMysqlTableSink::read_from_in_protocol(i_prot)?;
          f_5 = Some(val);
        },
        6 => {
          let val = TExportSink::read_from_in_protocol(i_prot)?;
          f_6 = Some(val);
        },
        7 => {
          let val = TOlapTableSink::read_from_in_protocol(i_prot)?;
          f_7 = Some(val);
        },
        8 => {
          let val = TMemoryScratchSink::read_from_in_protocol(i_prot)?;
          f_8 = Some(val);
        },
        9 => {
          let val = TOdbcTableSink::read_from_in_protocol(i_prot)?;
          f_9 = Some(val);
        },
        10 => {
          let val = TResultFileSink::read_from_in_protocol(i_prot)?;
          f_10 = Some(val);
        },
        11 => {
          let val = TJdbcTableSink::read_from_in_protocol(i_prot)?;
          f_11 = Some(val);
        },
        12 => {
          let val = TMultiCastDataStreamSink::read_from_in_protocol(i_prot)?;
          f_12 = Some(val);
        },
        13 => {
          let val = THiveTableSink::read_from_in_protocol(i_prot)?;
          f_13 = Some(val);
        },
        14 => {
          let val = TIcebergTableSink::read_from_in_protocol(i_prot)?;
          f_14 = Some(val);
        },
        15 => {
          let val = TDictionarySink::read_from_in_protocol(i_prot)?;
          f_15 = Some(val);
        },
        16 => {
          let val = TBlackholeSink::read_from_in_protocol(i_prot)?;
          f_16 = Some(val);
        },
        _ => {
          i_prot.skip(field_ident.field_type)?;
        },
      };
      i_prot.read_field_end()?;
    }
    i_prot.read_struct_end()?;
    verify_required_field_exists("TDataSink.type_", &f_1)?;
    let ret = TDataSink {
      type_: f_1.expect("auto-generated code should have checked for presence of required fields"),
      stream_sink: f_2,
      result_sink: f_3,
      mysql_table_sink: f_5,
      export_sink: f_6,
      olap_table_sink: f_7,
      memory_scratch_sink: f_8,
      odbc_table_sink: f_9,
      result_file_sink: f_10,
      jdbc_table_sink: f_11,
      multi_cast_stream_sink: f_12,
      hive_table_sink: f_13,
      iceberg_table_sink: f_14,
      dictionary_sink: f_15,
      blackhole_sink: f_16,
    };
    Ok(ret)
  }
  fn write_to_out_protocol(&self, o_prot: &mut dyn TOutputProtocol) -> thrift::Result<()> {
    let struct_ident = TStructIdentifier::new("TDataSink");
    o_prot.write_struct_begin(&struct_ident)?;
    o_prot.write_field_begin(&TFieldIdentifier::new("type", TType::I32, 1))?;
    self.type_.write_to_out_protocol(o_prot)?;
    o_prot.write_field_end()?;
    if let Some(ref fld_var) = self.stream_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("stream_sink", TType::Struct, 2))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.result_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("result_sink", TType::Struct, 3))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.mysql_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("mysql_table_sink", TType::Struct, 5))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.export_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("export_sink", TType::Struct, 6))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.olap_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("olap_table_sink", TType::Struct, 7))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.memory_scratch_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("memory_scratch_sink", TType::Struct, 8))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.odbc_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("odbc_table_sink", TType::Struct, 9))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.result_file_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("result_file_sink", TType::Struct, 10))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.jdbc_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("jdbc_table_sink", TType::Struct, 11))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.multi_cast_stream_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("multi_cast_stream_sink", TType::Struct, 12))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.hive_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("hive_table_sink", TType::Struct, 13))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.iceberg_table_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("iceberg_table_sink", TType::Struct, 14))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.dictionary_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("dictionary_sink", TType::Struct, 15))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    if let Some(ref fld_var) = self.blackhole_sink {
      o_prot.write_field_begin(&TFieldIdentifier::new("blackhole_sink", TType::Struct, 16))?;
      fld_var.write_to_out_protocol(o_prot)?;
      o_prot.write_field_end()?
    }
    o_prot.write_field_stop()?;
    o_prot.write_struct_end()
  }
}

